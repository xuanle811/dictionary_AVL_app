[
  {
    "term": "abductive logic programming (ALP)",
    "definition": "A high-level knowledge-representation framework that can be used to solve problems declaratively based on abductive reasoning. It extends normal logic programming by allowing some predicates to be incompletely defined, declared as abducible predicates."
  },
  {
    "term": "abductive reasoning",
    "definition": "A form of logical inference which starts with an observation or set of observations then seeks to find the simplest and most likely explanation. This process, unlike deductive reasoning, yields a plausible conclusion but does not positively verify it.[1] abductive"
  },
  {
    "term": "ablation",
    "definition": "The removal of a component of an AI system. An ablation study aims to determine the contribution of a component to an AI system by removing the component, and then"
  },
  {
    "term": "abstract data type",
    "definition": "A mathematical model for data types, where a data type is defined by its behavior (semantics) from the point of view of a user of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations."
  },
  {
    "term": "abstract data type (ADT)",
    "definition": "A mathematical model for data types in which a data type is defined by its behavior (semantics) from the point of view of a user of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations. This contrasts with data structures, which are concrete representations of data from the point of view of an implementer rather than a user."
  },
  {
    "term": "abstract method",
    "definition": "One with only a signature and no implementation body. It is often used to specify that a subclass must provide an implementation of the method. Abstract methods are used to specify interfaces"
  },
  {
    "term": "abstraction",
    "definition": "1. In software engineering and computer science, the process of removing physical, spatial, or temporal details[2] or attributes in the study of objects or systems in order to more closely attend to other details of interest;[3] it is also very similar in nature to the process of generalization. 2. The result of this process: an abstract concept-object created by keeping common features or attributes to various concrete objects or systems of study.[3]"
  },
  {
    "term": "accelerating change",
    "definition": "A perceived increase in the rate of technological change throughout history, which may suggest faster and more profound change in the future and may or may not be accompanied by equally profound social and cultural change."
  },
  {
    "term": "according to the desired total order);",
    "definition": "2. The output is a permutation (a reordering, yet retaining all of the original elements) of the input. Further, the input data is often stored in an array, which allows random access, rather than a list, which only allows sequential access; though many algorithms can be applied to either type of data after suitable modification."
  },
  {
    "term": "action language",
    "definition": "A language for specifying state transition systems, and is commonly used to create formal models of the effects of actions on the world.[6] Action languages are commonly used in the artificial intelligence and robotics domains, where they describe how actions affect the states of systems over time, and may be used for automated planning."
  },
  {
    "term": "action model learning",
    "definition": "An area of machine learning concerned with creation and modification of software agent's knowledge about effects and preconditions of the actions that can be executed within its environment. This knowledge is usually represented in logic-based action description language and used as the input for automated planners."
  },
  {
    "term": "action selection",
    "definition": "A way of characterizing the most basic problem of intelligent systems: what to do next. In artificial intelligence and computational cognitive science, \"the action selection problem\" is typically associated with intelligent agents and animats-artificial systems that exhibit complex behaviour in an agent environment."
  },
  {
    "term": "activation function",
    "definition": "In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs."
  },
  {
    "term": "adaptive algorithm",
    "definition": "An algorithm that changes its behavior at the time it is run, based on a priori defined reward mechanism or criterion."
  },
  {
    "term": "adaptive neuro fuzzy inference system (ANFIS)",
    "definition": "A kind of artificial neural network that is based on Takagi–Sugeno fuzzy inference system. The technique was developed in the early 1990s.[7][8] Since it integrates both neural networks and fuzzy logic principles, it has potential to capture the benefits of both in a single framework. Its inference system corresponds to a set of fuzzy IF–THEN rules that have learning capability to approximate nonlinear functions.[9] Hence, ANFIS is considered to be a universal estimator.[10] For using the ANFIS in a more efficient and optimal way, one can use the best parameters obtained by genetic algorithm.[11][12]"
  },
  {
    "term": "admissible heuristic",
    "definition": "In computer science, specifically in algorithms related to pathfinding, a heuristic function is said to be admissible if it never overestimates the cost of reaching the goal, i.e. the cost it estimates to reach the goal is not higher than the lowest possible cost from the current"
  },
  {
    "term": "affective computing",
    "definition": "The study and development of systems and devices that can recognize, interpret, process, and simulate human affects. Affective computing is an interdisciplinary field spanning computer science, psychology, and cognitive science.[14][15]"
  },
  {
    "term": "agent architecture",
    "definition": "A blueprint for software agents and intelligent control systems depicting the arrangement of components. The architectures implemented by intelligent agents are referred to as cognitive"
  },
  {
    "term": "agent-based model (ABM)",
    "definition": "A class of computational models for simulating the actions and interactions of autonomous agents (both individual or collective entities such as organizations or groups) with a view to assessing their effects on the system as a whole. It combines elements of game theory, complex systems, emergence, computational sociology, multi-agent systems, and evolutionary programming. Monte Carlo methods are used to introduce randomness."
  },
  {
    "term": "aggregate function",
    "definition": "In database management, a function in which the values of multiple rows are grouped together to form a single value of more significant meaning or measurement, such as a sum, count, or"
  },
  {
    "term": "agile software development",
    "definition": "An approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s).[6] It advocates adaptive planning, evolutionary development, early delivery, and continual improvement, and it encourages rapid and flexible response to change.[7]"
  },
  {
    "term": "AI accelerator",
    "definition": "A class of microprocessor [17] or computer system[18] designed as hardware acceleration for artificial intelligence applications, especially artificial neural networks, machine vision, and machine learning. AI-complete In the field of artificial intelligence, the most difficult problems are informally known as AI- complete or AI-hard, implying that the difficulty of these computational problems is equivalent to that of solving the central artificial intelligence problem-making computers as intelligent as people, or strong AI.[19] To call a problem AI-complete reflects an attitude that it would not be solved by a simple specific algorithm."
  },
  {
    "term": "algorithm",
    "definition": "An unambiguous specification of how to solve a class of problems. Algorithms can perform calculation, data processing, and automated reasoning tasks. They are ubiquitous in computing technologies."
  },
  {
    "term": "algorithm design",
    "definition": "A method or mathematical process for problem-solving and for engineering algorithms. The design of algorithms is part of many solution theories of operation research, such as dynamic programming and divide-and-conquer. Techniques for designing and implementing algorithm designs are also called algorithm design patterns,[8] such as the template method pattern and decorator pattern."
  },
  {
    "term": "algorithmic efficiency",
    "definition": "A property of an algorithm which relates to the number of computational resources used by the algorithm. An algorithm must be analyzed to determine its resource usage, and the efficiency of an algorithm can be measured based on usage of different resources. Algorithmic efficiency can be thought of as analogous to engineering productivity for a repeating or continuous process."
  },
  {
    "term": "algorithmic probability",
    "definition": "In algorithmic information theory, algorithmic probability, also known as Solomonoff probability, is a mathematical method of assigning a prior probability to a given observation. It was invented by Ray Solomonoff in the 1960s.[20] AlphaGo A computer program that plays the board game Go.[21] It was developed by Alphabet Inc.'s Google DeepMind in London. AlphaGo has several versions including AlphaGo Zero, AlphaGo Master, AlphaGo Lee, etc.[22] In October 2015, AlphaGo became the first computer Go program to beat a human professional Go player without handicaps on a"
  },
  {
    "term": "ambient intelligence (AmI)",
    "definition": "Electronic environments that are sensitive and responsive to the presence of people."
  },
  {
    "term": "American Standard Code for Information Interchange (ASCII)",
    "definition": "A character encoding standard for electronic communications. ASCII codes represent text in computers, telecommunications equipment, and other devices. Most modern character- encoding schemes are based on ASCII, although they support many additional characters."
  },
  {
    "term": "analysis of algorithms",
    "definition": "The determination of the computational complexity of algorithms, that is the amount of time, storage and/or other resources necessary to execute them. Usually, this involves determining a function that relates the length of an algorithm's input to the number of steps it takes (its time complexity) or the number of storage locations it uses (its space complexity)."
  },
  {
    "term": "analytics",
    "definition": "The discovery, interpretation, and communication of meaningful patterns in data."
  },
  {
    "term": "answer set programming (ASP)",
    "definition": "A form of declarative programming oriented towards difficult (primarily NP-hard) search problems. It is based on the stable model (answer set) semantics of logic programming. In ASP, search problems are reduced to computing stable models, and answer set solvers- programs for generating stable models-are used to perform search."
  },
  {
    "term": "ant colony optimization (ACO)",
    "definition": "A probabilistic technique for solving computational problems that can be reduced to finding good paths through graphs."
  },
  {
    "term": "anytime algorithm",
    "definition": "An algorithm that can return a valid solution to a problem even if it is interrupted before it ends."
  },
  {
    "term": "application programming interface (API)",
    "definition": "A set of subroutine definitions, communication protocols, and tools for building software. In general terms, it is a set of clearly defined methods of communication among various components. A good API makes it easier to develop a computer program by providing all the building blocks, which are then put together by the programmer."
  },
  {
    "term": "application software",
    "definition": "Computer software designed to perform a group of coordinated functions, tasks, or activities for the benefit of the user. Common examples of applications include word processors, spreadsheets, accounting applications, web browsers, media players, aeronautical flight simulators, console games, and photo editors. This contrasts with system software, which is mainly involved with managing the computer's most basic running operations, often without direct input from the user. The collective noun application software refers to all applications"
  },
  {
    "term": "approximate string matching",
    "definition": "The technique of finding strings that match a pattern approximately (rather than exactly). The problem of approximate string matching is typically divided into two sub-problems: finding approximate substring matches inside a given string and finding dictionary strings that match the pattern approximately."
  },
  {
    "term": "approximation error",
    "definition": "The discrepancy between an exact value and some approximation to it."
  },
  {
    "term": "argumentation framework",
    "definition": "A way to deal with contentious information and draw conclusions from it. In an abstract argumentation framework,[25] entry-level information is a set of abstract arguments that, for instance, represent data or a proposition. Conflicts between arguments are represented by a binary relation on the set of arguments. In concrete terms, you represent an argumentation framework with a directed graph such that the nodes are the arguments, and the arrows represent the attack relation. There exist some extensions of the Dung's framework, like the logic-based argumentation frameworks[26] or the value-"
  },
  {
    "term": "array data structure",
    "definition": "A data structure consisting of a collection of elements (values or variables), each identified by at least one array index or key. An array is stored such that the position of each element can be computed from its index tuple by a mathematical formula.[10][11][12] The simplest type of data structure is a linear array, also called a one-dimensional array."
  },
  {
    "term": "artifact",
    "definition": "One of many kinds of tangible by-products produced during the development of software. Some artifacts (e.g. use cases, class diagrams, and other Unified Modeling Language (UML) models, requirements, and design documents) help describe the function, architecture, and design of software. Other artifacts are concerned with the process of development itself-such as project plans, business cases, and risk assessments."
  },
  {
    "term": "artificial general intelligence (AGI)",
    "definition": "A type of AI that matches or surpasses human cognitive capabilities across a wide range of cognitive tasks."
  },
  {
    "term": "artificial immune system (AIS)",
    "definition": "A class of computationally intelligent, rule-based machine learning systems inspired by the principles and processes of the vertebrate immune system. The algorithms are typically modeled after the immune system's characteristics of learning and memory for use in problem-solving."
  },
  {
    "term": "artificial intelligence (AI)",
    "definition": "Intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and other animals. In computer science, AI research is defined as the study of \"intelligent agents\": devices capable of perceiving their environment and taking actions that maximize the chance of successfully achieving their goals.[13] Colloquially, the term \"artificial intelligence\" is applied when a machine mimics \"cognitive\" functions that humans associate with other human minds, such as \"learning\" and \"problem solving\".[14] ASCII See American Standard Code for Information Interchange."
  },
  {
    "term": "Artificial Intelligence Markup Language",
    "definition": "An XML dialect for creating natural language software agents. Association for the Advancement of Artificial Intelligence (AAAI) An international, nonprofit, scientific society devoted to promote research in, and responsible use of, artificial intelligence. AAAI also aims to increase public understanding of artificial intelligence (AI), improve the teaching and training of AI practitioners, and provide guidance for research planners and funders concerning the importance and potential of current AI developments and future directions.[30]"
  },
  {
    "term": "assertion",
    "definition": "In computer programming, a statement that a predicate (Boolean-valued function, i.e. a true– false expression) is always true at that point in code execution. It can help a programmer read the code, help a compiler compile it, or help the program detect its own defects. For the latter, some programs check assertions by actually evaluating the predicate as they run and if it is not in fact true – an assertion failure – the program considers itself to be broken and typically deliberately crashes or throws an assertion failure exception."
  },
  {
    "term": "associative array",
    "definition": "An associative array, map, symbol table, or dictionary is an abstract data type composed of a collection of (key, value) pairs, such that each possible key appears at most once in the collection. Operations associated with this data type allow:[15][16]"
  },
  {
    "term": "asymptotic computational complexity",
    "definition": "In computational complexity theory, asymptotic computational complexity is the usage of asymptotic analysis for the estimation of computational complexity of algorithms and computational problems, commonly associated with the usage of the big O notation."
  },
  {
    "term": "attention mechanism",
    "definition": "Machine learning-based attention is a mechanism mimicking cognitive attention. It calculates \"soft\" weights for each word, more precisely for its embedding, in the context window. It can do it either in parallel (such as in transformers) or sequentially (such as in recursive neural networks). \"Soft\" weights can change during each runtime, in contrast to \"hard\" weights, which are (pre-)trained and fine-tuned and remain frozen afterwards. Multiple attention heads are used in transformer-based large language models."
  },
  {
    "term": "attributional calculus",
    "definition": "A logic and representation system defined by Ryszard S. Michalski. It combines elements of predicate logic, propositional calculus, and multi-valued logic. Attributional calculus provides a formal language for natural induction, an inductive learning process whose results are in forms natural to people."
  },
  {
    "term": "augmented reality (AR)",
    "definition": "An interactive experience of a real-world environment where the objects that reside in the real-world are \"augmented\" by computer-generated perceptual information, sometimes across multiple sensory modalities, including visual, auditory, haptic, somatosensory, and"
  },
  {
    "term": "autoencoder",
    "definition": "A type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning). A common implementation is the variational autoencoder (VAE)."
  },
  {
    "term": "automata theory",
    "definition": "The study of abstract machines and automata, as well as the computational problems that can be solved using them. It is a theory in theoretical computer science and discrete mathematics (a subject of study in both mathematics and computer science)."
  },
  {
    "term": "automated machine learning (AutoML)",
    "definition": "A field of machine learning (ML) which aims to automatically configure an ML system to maximize its performance (e.g, classification accuracy)."
  },
  {
    "term": "automated planning and scheduling",
    "definition": "A branch of artificial intelligence that concerns the realization of strategies or action sequences, typically for execution by intelligent agents, autonomous robots and unmanned vehicles. Unlike classical control and classification problems, the solutions are complex and must be discovered and optimized in multidimensional space. Planning is"
  },
  {
    "term": "automated reasoning",
    "definition": "An area of computer science and mathematical logic dedicated to understanding different aspects of reasoning. The study of automated reasoning helps produce computer programs that allow computers to reason completely, or nearly completely, automatically. Although automated reasoning is considered a sub-field of artificial intelligence, it also has connections with theoretical computer science, and even philosophy. B"
  },
  {
    "term": "autonomic computing (AC)",
    "definition": "The self-managing characteristics of distributed computing resources, adapting to unpredictable changes while hiding intrinsic complexity to operators and users. Initiated by IBM in 2001, this initiative ultimately aimed to develop computer systems capable of self- management, to overcome the rapidly growing complexity of computing systems management, and to reduce the barrier that complexity poses to further growth.[33]"
  },
  {
    "term": "autonomous car",
    "definition": "A vehicle that is capable of sensing its environment and moving with little or no human"
  },
  {
    "term": "autonomous robot",
    "definition": "A robot that performs behaviors or tasks with a high degree of autonomy. Autonomous robotics is usually considered to be a subfield of artificial intelligence, robotics, and information engineering.[37]"
  },
  {
    "term": "backpropagation",
    "definition": "A method used in artificial neural networks to calculate a gradient that is needed in the calculation of the weights to be used in the network.[38] Backpropagation is shorthand for \"the backward propagation of errors\", since an error is computed at the output and distributed backwards throughout the network's layers. It is commonly used to train deep neural networks,[39] a term referring to neural networks with more than one hidden"
  },
  {
    "term": "backpropagation through structure (BPTS)",
    "definition": "A gradient-based technique for training recurrent neural networks, proposed in a 1996"
  },
  {
    "term": "backpropagation through time (BPTT)",
    "definition": "A gradient-based technique for training certain types of recurrent neural networks, such as Elman networks. The algorithm was independently derived by numerous"
  },
  {
    "term": "backward chaining",
    "definition": "An inference method described colloquially as working backward from the goal. It is used in automated theorem provers, inference engines, proof assistants, and other artificial"
  },
  {
    "term": "bag-of-words model",
    "definition": "A simplifying representation used in natural language processing and information retrieval (IR). In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity. The bag-of-words model has also been used for computer vision.[46] The bag-of-words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.[47]"
  },
  {
    "term": "bag-of-words model in computer vision",
    "definition": "In computer vision, the bag-of-words model (BoW model) can be applied to image classification, by treating image features as words. In document classification, a bag of words is a sparse vector of occurrence counts of words; that is, a sparse histogram over the vocabulary. In computer vision, a bag of visual words is a vector of occurrence counts of a vocabulary of local image features."
  },
  {
    "term": "bandwidth",
    "definition": "The maximum rate of data transfer across a given path. Bandwidth may be characterized as network bandwidth,[17] data bandwidth,[18] or digital bandwidth.[19][20]"
  },
  {
    "term": "batch normalization",
    "definition": "A technique for improving the performance and stability of artificial neural networks. It is a technique to provide any layer in a neural network with inputs that are zero mean/unit variance.[48] Batch normalization was introduced in a 2015 paper.[49][50] It is used to normalize the input layer by adjusting and scaling the activations."
  },
  {
    "term": "Bayesian programming",
    "definition": "A formalism and a methodology for having a technique to specify probabilistic models and solve problems when less than the necessary information is available."
  },
  {
    "term": "bees algorithm",
    "definition": "A population-based search algorithm which was developed by Pham, Ghanbarzadeh and et al. in 2005.[51] It mimics the food foraging behaviour of honey bee colonies. In its basic version the algorithm performs a kind of neighborhood search combined with global search, and can be used for both combinatorial optimization and continuous optimization. The only condition for the application of the bees algorithm is that some measure of distance between the solutions is defined. The effectiveness and specific abilities of the bees algorithm have been proven in a number of studies.[52][53][54][55]"
  },
  {
    "term": "behavior informatics (BI)",
    "definition": "The informatics of behaviors so as to obtain behavior intelligence and behavior"
  },
  {
    "term": "behavior tree (BT)",
    "definition": "A mathematical model of plan execution used in computer science, robotics, control systems and video games. They describe switchings between a finite set of tasks in a modular fashion. Their strength comes from their ability to create very complex tasks composed of simple tasks, without worrying how the simple tasks are implemented. BTs present some similarities to hierarchical state machines with the key difference that the main building block of a behavior is a task rather than a state. Its ease of human understanding make BTs less error-prone and very popular in the game developer community. BTs have shown to generalize several other control architectures.[57][58]"
  },
  {
    "term": "belief–desire–intention software model (BDI)",
    "definition": "A software model developed for programming intelligent agents. Superficially characterized by the implementation of an agent's beliefs, desires and intentions, it actually uses these concepts to solve a particular problem in agent programming. In essence, it provides a mechanism for separating the activity of selecting a plan (from a plan library or an external planner application) from the execution of currently active plans. Consequently, BDI agents are able to balance the time spent on deliberating about plans (choosing what to do) and executing those plans (doing it). A third activity, creating the plans in the first place (planning), is not within the scope of the model, and is left to the system designer and programmer."
  },
  {
    "term": "benchmark",
    "definition": "The act of running a computer program, a set of programs, or other operations, in order to assess the relative performance of an object, normally by running a number of standard tests and trials against it.[21] The term benchmark is also commonly utilized for the purposes of elaborately designed benchmarking programs themselves."
  },
  {
    "term": "best, worst and average case",
    "definition": "Expressions of what the resource usage is at least, at most, and on average, respectively, for a given algorithm. Usually the resource being considered is running time, i.e. time complexity, but it could also be memory or some other resource. Best case is the function which performs the minimum number of steps on input data of n elements; worst case is the function which performs the maximum number of steps on input data of size n; average case is the function which performs an average number of steps on input data of n elements."
  },
  {
    "term": "bias–variance tradeoff",
    "definition": "In statistics and machine learning, the bias–variance tradeoff is the property of a set of predictive models whereby models with a lower bias in parameter estimation have a higher variance of the parameter estimates across samples, and vice versa."
  },
  {
    "term": "big data",
    "definition": "A term used to refer to data sets that are too large or complex for traditional data-processing application software to adequately deal with. Data with many cases (rows) offer greater statistical power, while data with higher complexity (more attributes or columns) may lead to a"
  },
  {
    "term": "big O notation",
    "definition": "A mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity. It is a member of a family of notations invented by Paul Bachmann,[23] Edmund Landau,[24] and others, collectively called Bachmann–Landau notation or asymptotic notation."
  },
  {
    "term": "Big O notation",
    "definition": "A mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity. It is a member of a family of notations invented by Paul Bachmann,[60] Edmund Landau,[61] and others, collectively called Bachmann–Landau notation or asymptotic notation."
  },
  {
    "term": "binary number",
    "definition": "In mathematics and digital electronics, a number expressed in the base-2 numeral system or binary numeral system, which uses only two symbols: typically 0 (zero) and 1 (one)."
  },
  {
    "term": "binary search algorithm",
    "definition": "A search algorithm that finds the position of a target value within a sorted array.[28]"
  },
  {
    "term": "binary tree",
    "definition": "A tree data structure in which each node has at most two children, which are referred to as the left child and the right child. A recursive definition using just set theory notions is that a (non- empty) binary tree is a tuple (L, S, R), where L and R are binary trees or the empty set and S is a singleton set.[29] Some authors allow the binary tree to be the empty set as well.[30]"
  },
  {
    "term": "bioinformatics",
    "definition": "An interdisciplinary field that combines biology, computer science, information engineering, mathematics, and statistics to develop methods and software tools for analyzing and interpreting biological data. Bioinformatics is widely used for in silico analyses of biological queries using mathematical and statistical techniques."
  },
  {
    "term": "bit",
    "definition": "A basic unit of information used in computing and digital communications; a portmanteau of binary digit. A binary digit can have one of two possible values, and may be physically represented with a two-state device. These state values are most commonly represented as"
  },
  {
    "term": "bit rate (R)",
    "definition": "In telecommunications and computing, the number of bits that are conveyed or processed per"
  },
  {
    "term": "blackboard system",
    "definition": "An artificial intelligence approach based on the blackboard architectural model,[64][65][66][67] where a common knowledge base, the \"blackboard\", is iteratively updated by a diverse group of specialist knowledge sources, starting with a problem specification and ending with a solution. Each knowledge source updates the blackboard with a partial solution when its internal constraints match the blackboard state. In this way, the specialists work together to solve the problem."
  },
  {
    "term": "blacklist",
    "definition": "In computing, a basic access control mechanism that allows through all elements (email addresses, users, passwords, URLs, IP addresses, domain names, file hashes, etc.), except those explicitly mentioned in a list of prohibited elements. Those items on the list are denied access. The opposite is a whitelist, which means only items on the list are allowed through whatever gate is being used while all other elements are blocked. A greylist contains items that are temporarily blocked (or temporarily allowed) until an additional step is performed."
  },
  {
    "term": "BMP file format",
    "definition": "A raster graphics image file format used to store bitmap digital images independently of the display device (such as a graphics adapter), used especially on Microsoft Windows [33] and OS/2[34] operating systems."
  },
  {
    "term": "Boltzmann machine",
    "definition": "A type of stochastic recurrent neural network and Markov random field.[68] Boltzmann machines can be seen as the stochastic, generative counterpart of Hopfield networks."
  },
  {
    "term": "Boolean algebra",
    "definition": "In mathematics and mathematical logic, the branch of algebra in which the values of the variables are the truth values true and false, usually denoted 1 and 0, respectively. Contrary to elementary algebra, where the values of the variables are numbers and the prime operations are addition and multiplication, the main operations of Boolean algebra are the conjunction and (denoted as ∧), the disjunction or (denoted as ∨), and the negation not (denoted as ¬).[37] It is thus a formalism for describing logical relations in the same way that elementary algebra describes numeric relations."
  },
  {
    "term": "Boolean data type",
    "definition": "A data type that has one of two possible values (usually denoted true and false), intended to represent the two truth values of logic and Boolean algebra. It is named after George Boole, who first defined an algebraic system of logic in the mid-19th century. The Boolean data type is primarily associated with conditional statements, which allow different actions by changing control flow depending on whether a programmer-specified Boolean condition evaluates to true or false.[35] It is a special case of a more general logical data type (see propositional logic)-i.e. logic need not always be Boolean."
  },
  {
    "term": "Boolean expression",
    "definition": "An expression used in a programming language that returns a Boolean value when evaluated, that is one of true or false. A Boolean expression may be composed of a combination of the Boolean constants true or false, Boolean-typed variables, Boolean-valued operators, and Boolean-valued functions.[36]"
  },
  {
    "term": "Boolean satisfiability problem",
    "definition": "The problem of determining if there exists an interpretation that satisfies a given Boolean formula. In other words, it asks whether the variables of a given Boolean formula can be consistently replaced by the values TRUE or FALSE in such a way that the formula evaluates to TRUE. If this is the case, the formula is called satisfiable. On the other hand, if no such assignment exists, the function expressed by the formula is FALSE for all possible variable assignments and the formula is unsatisfiable. For example, the formula \"a AND NOT b\" is satisfiable because one can find the values a = TRUE and b = FALSE, which make (a AND NOT b) = TRUE. In contrast, \"a AND NOT a\" is unsatisfiable."
  },
  {
    "term": "boosting",
    "definition": "A machine learning ensemble metaheuristic for primarily reducing bias (as opposed to variance), by training models sequentially, each one correcting the errors of its predecessor."
  },
  {
    "term": "booting",
    "definition": "The procedures implemented in starting up a computer or computer appliance until it can be used. It can be initiated by hardware such as a button press or by a software command. After the power is switched on, the computer is relatively dumb and can read only part of its storage called read-only memory. There, a small program is stored called firmware. It does power-on self-tests and, most importantly, allows access to other types of memory like a hard disk and main memory. The firmware loads bigger programs into the computer's main memory and runs it. C"
  },
  {
    "term": "bootstrap aggregating",
    "definition": "A machine learning ensemble metaheuristic for primarily reducing variance (as opposed to bias), by training multiple models independently and averaging their predictions."
  },
  {
    "term": "brain technology",
    "definition": "A technology that employs the latest findings in neuroscience. The term was first introduced by the Artificial Intelligence Laboratory in Zurich, Switzerland, in the context of the ROBOY project.[69] Brain Technology can be employed in robots,[70] know-how management systems [71] and any other application with self-learning capabilities. In particular, Brain Technology applications allow the visualization of the underlying learning architecture often coined as \"know-how maps\"."
  },
  {
    "term": "branching factor",
    "definition": "In computing, tree data structures, and game theory, the number of children at each node, the outdegree. If this value is not uniform, an average branching factor can be calculated."
  },
  {
    "term": "brute-force search",
    "definition": "A very general problem-solving technique and algorithmic paradigm that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement. C"
  },
  {
    "term": "byte",
    "definition": "A unit of digital information that most commonly consists of eight bits, representing a binary number. Historically, the byte was the number of bits used to encode a single character of text in a computer[38][39] and for this reason it is the smallest addressable unit of memory in many computer architectures."
  },
  {
    "term": "callback",
    "definition": "Any executable code that is passed as an argument to other code that is expected to \"call back\" (execute) the argument at a given time. This execution may be immediate, as in a synchronous callback, or it might happen at a later time, as in an asynchronous callback."
  },
  {
    "term": "capsule neural network (CapsNet)",
    "definition": "A machine learning system that is a type of artificial neural network (ANN) that can be used to better model hierarchical relationships. The approach is an attempt to more"
  },
  {
    "term": "case-based reasoning (CBR)",
    "definition": "Broadly construed, the process of solving new problems based on the solutions of similar past problems."
  },
  {
    "term": "central processing unit (CPU)",
    "definition": "The electronic circuitry within a computer that carries out the instructions of a computer program by performing the basic arithmetic, logic, controlling, and input/output (I/O) operations specified by the instructions. The computer industry has used the term \"central processing unit\" at least since the early 1960s.[40] Traditionally, the term \"CPU\" refers to a processor, more specifically to its processing unit and control unit (CU), distinguishing these core elements of a computer from external components such as main memory and I/O circuitry.[41]"
  },
  {
    "term": "character",
    "definition": "A unit of information that roughly corresponds to a grapheme, grapheme-like unit, or symbol, such as in an alphabet or syllabary in the written form of a natural language.[42] CI/CD See: continuous integration (CI) / continuous delivery (CD)."
  },
  {
    "term": "chatbot",
    "definition": "A computer program or an artificial intelligence which conducts a conversation via auditory"
  },
  {
    "term": "cipher",
    "definition": "In cryptography, an algorithm for performing encryption or decryption-a series of well-defined steps that can be followed as a procedure."
  },
  {
    "term": "class",
    "definition": "In object-oriented programming, an extensible program-code-template for creating objects, providing initial values for state (member variables) and implementations of behavior (member functions or methods).[43][44] In many languages, the class name is used as the name for the class (the template itself), the name for the default constructor of the class (a subroutine that creates objects), and as the type of objects generated by instantiating the class; these distinct"
  },
  {
    "term": "class-based programming",
    "definition": "A style of object-oriented programming (OOP) in which inheritance occurs via defining \"classes\" of objects, instead of via the objects alone (compare prototype-based programming)."
  },
  {
    "term": "cleanroom software engineering",
    "definition": "A software development process intended to produce software with a certifiable level of reliability. The cleanroom process was originally developed by Harlan Mills and several of his colleagues including Alan Hevner at IBM.[46] The focus of the cleanroom process is on defect prevention, rather than defect removal."
  },
  {
    "term": "client",
    "definition": "A piece of computer hardware or software that accesses a service made available by a server. The server is often (but not always) on another computer system, in which case the client accesses the service by way of a network.[45] The term applies to the role that programs or devices play in the client–server model."
  },
  {
    "term": "closure",
    "definition": "A technique for implementing lexically scoped name binding in a language with first-class functions. Operationally, a closure is a record storing a function [a] together with an"
  },
  {
    "term": "cloud computing",
    "definition": "Shared pools of configurable computer system resources and higher-level services that can be rapidly provisioned with minimal management effort, often over the Internet. Cloud computing relies on sharing of resources to achieve coherence and economies of scale, similar to a public utility."
  },
  {
    "term": "cloud robotics",
    "definition": "A field of robotics that attempts to invoke cloud technologies such as cloud computing, cloud storage, and other Internet technologies centred on the benefits of converged infrastructure and shared services for robotics. When connected to the cloud, robots can benefit from the powerful computation, storage, and communication resources of modern data center in the cloud, which can process and share information from various robots or agent (other machines, smart objects, humans, etc.). Humans can also delegate tasks to robots remotely through networks. Cloud computing technologies enable robot systems to be endowed with powerful capability whilst reducing costs through cloud technologies. Thus, it is possible to build lightweight, low cost, smarter robots have intelligent \"brain\" in the cloud. The \"brain\" consists of data center, knowledge base, task planners, deep learning, information processing, environment models, communication support,"
  },
  {
    "term": "cluster analysis",
    "definition": "The task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters). It is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, bioinformatics, data compression, and computer graphics. Cobweb An incremental system for hierarchical conceptual clustering. COBWEB was invented by Professor Douglas H. Fisher, currently at Vanderbilt University.[78][79] COBWEB incrementally organizes observations into a classification tree. Each node in a classification tree represents a class (concept) and is labeled by a probabilistic concept that summarizes the attribute-value distributions of objects classified under the node. This classification tree can be used to predict missing attributes or the class of a new object.[80]"
  },
  {
    "term": "code library",
    "definition": "A collection of non-volatile resources used by computer programs, often for software development. These may include configuration data, documentation, help data, message templates, pre-written code and subroutines, classes, values or type specifications. In IBM's OS/360 and its successors they are referred to as partitioned data sets code"
  },
  {
    "term": "coding",
    "definition": "Computer programming is the process of designing and building an executable computer program for accomplishing a specific computing task. Programming involves tasks such as analysis, generating algorithms, profiling algorithms' accuracy and resource consumption, and the implementation of algorithms in a chosen programming language (commonly referred to as coding[48][49]). The source code of a program is written in one or more programming languages. The purpose of programming is to find a sequence of instructions that will automate the performance of a task for solving a given problem. The process of programming thus often requires expertise in several different subjects, including knowledge of the application domain, specialized algorithms, and formal logic."
  },
  {
    "term": "coding theory",
    "definition": "The study of the properties of codes and their respective fitness for specific applications. Codes are used for data compression, cryptography, error detection and correction, data transmission and data storage. Codes are studied by various scientific disciplines-such as information theory, electrical engineering, mathematics, linguistics, and computer science-for the purpose of designing efficient and reliable data transmission methods. This typically involves the removal of redundancy and the correction or detection of errors in the transmitted data."
  },
  {
    "term": "cognitive architecture",
    "definition": "The Institute of Creative Technologies defines cognitive architecture as: \"hypothesis about the fixed structures that provide a mind, whether in natural or artificial systems, and how they work together – in conjunction with knowledge and skills embodied within the architecture – to yield intelligent behavior in a diversity of complex environments.\"[81]"
  },
  {
    "term": "cognitive computing",
    "definition": "In general, the term cognitive computing has been used to refer to new hardware and/or software that mimics the functioning of the human brain[82][83][84][85][86][87] and helps to improve human decision-making.[88] In this sense, CC is a new type of computing with the goal of more accurate models of how the human brain/mind senses, reasons, and responds to stimulus."
  },
  {
    "term": "cognitive science",
    "definition": "The interdisciplinary, scientific study of the mind and its processes.[50] It examines the nature, the tasks, and the functions of cognition (in a broad sense). Cognitive scientists study intelligence and behavior, with a focus on how nervous systems represent, process, and transform information. Mental faculties of concern to cognitive scientists include language, perception, memory, attention, reasoning, and emotion; to understand these faculties, cognitive scientists borrow from fields such as linguistics, psychology, artificial intelligence, philosophy,"
  },
  {
    "term": "collection",
    "definition": "A collection or container is a grouping of some variable number of data items (possibly zero) that have some shared significance to the problem being solved and need to be operated upon together in some controlled fashion. Generally, the data items will be of the same type or, in languages supporting inheritance, derived from some common ancestor type. A collection is a concept applicable to abstract data types, and does not prescribe a specific implementation as a concrete data structure, though often there is a conventional choice (see Container for type theory discussion)."
  },
  {
    "term": "columns)",
    "definition": "nan"
  },
  {
    "term": "combinatorial optimization",
    "definition": "In Operations Research, applied mathematics and theoretical computer science, combinatorial optimization is a topic that consists of finding an optimal object from a finite"
  },
  {
    "term": "comma-separated values (CSV)",
    "definition": "A delimited text file that uses a comma to separate values. A CSV file stores tabular data (numbers and text) in plain text. Each line of the file is a data record. Each record consists of one or more fields, separated by commas. The use of the comma as a field separator is the source of the name for this file format."
  },
  {
    "term": "committee machine",
    "definition": "A type of artificial neural network using a divide and conquer strategy in which the responses of multiple neural networks (experts) are combined into a single response.[91] The combined response of the committee machine is supposed to be superior to those of its constituent experts. Compare ensembles of classifiers."
  },
  {
    "term": "commonsense knowledge",
    "definition": "In artificial intelligence research, commonsense knowledge consists of facts about the everyday world, such as \"Lemons are sour\", that all humans are expected to know. The first AI program to address common sense knowledge was Advice Taker in 1959 by John McCarthy.[92]"
  },
  {
    "term": "commonsense reasoning",
    "definition": "A branch of artificial intelligence concerned with simulating the human ability to make presumptions about the type and essence of ordinary situations they encounter every"
  },
  {
    "term": "compiler",
    "definition": "A computer program that transforms computer code written in one programming language (the source language) into another programming language (the target language). Compilers are a type of translator that support digital devices, primarily computers. The name compiler is primarily used for programs that translate source code from a high-level programming language to a lower-level language (e.g. assembly language, object code, or machine code) to create an"
  },
  {
    "term": "computability theory",
    "definition": "also known as recursion theory, is a branch of mathematical logic, of computer science, and of the theory of computation that originated in the 1930s with the study of computable functions and Turing degrees. The field has since expanded to include the study of generalized computability and definability. In these areas, recursion theory overlaps with proof theory and effective descriptive set theory."
  },
  {
    "term": "computation",
    "definition": "Any type of calculation[53][54] that includes both arithmetical and non-arithmetical steps and follows a well-defined model, e.g. an algorithm. The study of computation is paramount to the discipline of computer science."
  },
  {
    "term": "computational biology",
    "definition": "Involves the development and application of data-analytical and theoretical methods, mathematical modelling and computational simulation techniques to the study of biological, ecological, behavioural, and social systems.[55] The field is broadly defined and includes foundations in biology, applied mathematics, statistics, biochemistry, chemistry, biophysics, molecular biology, genetics, genomics, computer science, and evolution.[56] Computational biology is different from biological computing, which is a subfield of computer science and computer engineering using bioengineering and biology to build computers."
  },
  {
    "term": "computational chemistry",
    "definition": "A branch of chemistry that uses computer simulation to assist in solving chemical problems. It uses methods of theoretical chemistry, incorporated into efficient computer programs, to calculate the structures and properties of molecules and solids."
  },
  {
    "term": "computational complexity theory",
    "definition": "A subfield of computational science which focuses on classifying computational problems according to their inherent difficulty, and relating these classes to each other. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm."
  },
  {
    "term": "computational creativity",
    "definition": "A multidisciplinary endeavour that includes the fields of artificial intelligence, cognitive psychology, philosophy, and the arts."
  },
  {
    "term": "computational cybernetics",
    "definition": "The integration of cybernetics and computational intelligence techniques."
  },
  {
    "term": "computational humor",
    "definition": "A branch of computational linguistics and artificial intelligence which uses computers in"
  },
  {
    "term": "computational intelligence (CI)",
    "definition": "Usually refers to the ability of a computer to learn a specific task from data or experimental observation."
  },
  {
    "term": "computational learning theory",
    "definition": "In computer science, computational learning theory (or just learning theory) is a subfield of artificial intelligence devoted to studying the design and analysis of machine learning"
  },
  {
    "term": "computational linguistics",
    "definition": "An interdisciplinary field concerned with the statistical or rule-based modeling of natural language from a computational perspective, as well as the study of appropriate computational approaches to linguistic questions."
  },
  {
    "term": "computational mathematics",
    "definition": "The mathematical research in areas of science where computing plays an essential role."
  },
  {
    "term": "computational model",
    "definition": "A mathematical model in computational science that requires extensive computational resources to study the behavior of a complex system by computer simulation.[57]"
  },
  {
    "term": "computational neuroscience",
    "definition": "A branch of neuroscience which employs mathematical models, theoretical analysis, and abstractions of the brain to understand the principles that govern the development, structure, physiology, and cognitive abilities of the nervous system.[58][59][60][61]"
  },
  {
    "term": "computational number theory",
    "definition": "The study of algorithms for performing number theoretic computations."
  },
  {
    "term": "computational physics",
    "definition": "Is the study and implementation of numerical analysis to solve problems in physics for which a quantitative theory already exists.[62] Historically, computational physics was the first application of modern computers in science, and is now a subset of computational science."
  },
  {
    "term": "computational problem",
    "definition": "In theoretical computer science, a computational problem is a mathematical object representing a collection of questions that computers might be able to solve."
  },
  {
    "term": "computational science",
    "definition": "An interdisciplinary field that uses advanced computing capabilities to understand and solve complex problems. It is an area of science which spans many disciplines, but at its core it involves the development of computer models and simulations to understand complex natural systems."
  },
  {
    "term": "computational statistics",
    "definition": "The interface between statistics and computer science."
  },
  {
    "term": "computational steering",
    "definition": "Is the practice of manually intervening with an otherwise autonomous computational process, to change its outcome."
  },
  {
    "term": "computer",
    "definition": "A device that can be instructed to carry out sequences of arithmetic or logical operations automatically via computer programming. Modern computers have the ability to follow generalized sets of operations, called programs. These programs enable computers to perform an extremely wide range of tasks."
  },
  {
    "term": "computer architecture",
    "definition": "A set of rules and methods that describe the functionality, organization, and implementation of computer systems. Some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation.[63] In other definitions computer architecture involves instruction set architecture design, microarchitecture design,"
  },
  {
    "term": "computer audition (CA)",
    "definition": "See machine listening."
  },
  {
    "term": "computer data storage",
    "definition": "A technology consisting of computer components and recording media that are used to retain digital data. Data storage is a core function and fundamental component of all modern computer"
  },
  {
    "term": "computer ethics",
    "definition": "A part of practical philosophy concerned with how computing professionals should make"
  },
  {
    "term": "computer graphics",
    "definition": "Pictures and films created using computers. Usually, the term refers to computer-generated image data created with the help of specialized graphical hardware and software. It is a vast and recently developed area of computer science."
  },
  {
    "term": "computer network",
    "definition": "A digital telecommunications network which allows nodes to share resources. In computer networks, computing devices exchange data with each other using connections (data links) between nodes. These data links are established over cable media such as wires or optic cables, or wireless media such as Wi-Fi."
  },
  {
    "term": "computer program",
    "definition": "Is a collection of instructions[67] that can be executed by a computer to perform a specific task."
  },
  {
    "term": "computer programming",
    "definition": "The process of designing and building an executable computer program for accomplishing a specific computing task. Programming involves tasks such as analysis, generating algorithms, profiling algorithms' accuracy and resource consumption, and the implementation of algorithms in a chosen programming language (commonly referred to as coding[48][49]). The source code of a program is written in one or more programming languages. The purpose of programming is to find a sequence of instructions that will automate the performance of a task for solving a given problem. The process of programming thus often requires expertise in several different subjects, including knowledge of the application domain, specialized algorithms, and formal logic."
  },
  {
    "term": "computer science",
    "definition": "The theory, experimentation, and engineering that form the basis for the design and use of computers. It involves the study of algorithms that process, store, and communicate digital information. A computer scientist specializes in the theory of computation and the design of"
  },
  {
    "term": "computer scientist",
    "definition": "A person who has acquired the knowledge of computer science, the study of the theoretical foundations of information and computation and their application."
  },
  {
    "term": "computer security",
    "definition": "The protection of computer systems from theft or damage to their hardware, software, or electronic data, as well as from disruption or misdirection of the services they provide."
  },
  {
    "term": "computer vision",
    "definition": "An interdisciplinary scientific field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do.[70][71][72]"
  },
  {
    "term": "computer-automated design (CAutoD)",
    "definition": "Design automation usually refers to electronic design automation, or Design Automation which is a Product Configurator. Extending Computer-Aided Design (CAD), automated design and computer-automated design[100][101][102] are concerned with a broader range of applications, such as automotive engineering, civil engineering,[103][104][105][106] composite material design, control engineering,[107] dynamic system identification and optimization,[108] financial systems, industrial equipment, mechatronic systems, steel construction,[109] structural optimisation,[110] and the invention of novel systems. More recently, traditional CAD simulation is seen to be transformed to CAutoD by biologically inspired machine learning,[111] including heuristic search techniques such as evolutionary computation,[112][113] and swarm intelligence algorithms.[114]"
  },
  {
    "term": "computing",
    "definition": "Is any goal-oriented activity requiring, benefiting from, or creating computing machinery. It includes study of algorithmic processes and development of both hardware and software. It has scientific, engineering, mathematical, technological and social aspects. Major computing fields include computer engineering, computer science, cybersecurity, data science, information systems, information technology and software engineering.[73]"
  },
  {
    "term": "concatenation",
    "definition": "Literally, \"a chaining together\" or the process of joining together things. In formal language theory and computer programming, string concatenation is the operation of joining character strings end-to-end. For example, the concatenation of \"snow\" and \"ball\" is \"snowball\".[74] In certain formalisations of concatenation theory, also called string theory, string concatenation is a primitive notion. Concurrency The ability of different parts or units of a program, algorithm, or problem to be executed out-of- order or in partial order, without affecting the final outcome. This allows for parallel execution of the concurrent units, which can significantly improve overall speed of the execution in multi- processor and multi-core systems. In more technical terms, concurrency refers to the decomposability property of a program, algorithm, or problem into order-independent or"
  },
  {
    "term": "concept drift",
    "definition": "In predictive analytics and machine learning, the concept drift means that the statistical properties of the target variable, which the model is trying to predict, change over time in unforeseen ways. This causes problems because the predictions become less accurate as time passes."
  },
  {
    "term": "conditional",
    "definition": "A feature of a programming language which performs different computations or actions depending on whether a programmer-specified Boolean condition evaluates to true or false. Apart from the case of branch predication, this is always achieved by selectively altering the control flow based on some condition."
  },
  {
    "term": "connectionism",
    "definition": "An approach in the fields of cognitive science, that hopes to explain mental phenomena"
  },
  {
    "term": "consistent heuristic",
    "definition": "In the study of path-finding problems in artificial intelligence, a heuristic function is said to be consistent, or monotone, if its estimate is always less than or equal to the estimated distance from any neighboring vertex to the goal, plus the cost of reaching that neighbor."
  },
  {
    "term": "constrained conditional model (CCM)",
    "definition": "A machine learning and inference framework that augments the learning of conditional (probabilistic or discriminative) models with declarative constraints."
  },
  {
    "term": "constraint logic programming",
    "definition": "A form of constraint programming, in which logic programming is extended to include concepts from constraint satisfaction. A constraint logic program is a logic program that contains constraints in the body of clauses. An example of a clause including a constraint is A(X,Y) :- X+Y>0, B(X), C(Y). In this clause, X+Y>0 is a constraint; A(X,Y), B(X), and C(Y) are literals as in regular logic programming. This clause states one condition under which the statement A(X,Y) holds: X+Y is greater than zero and both B(X) and C(Y) are true."
  },
  {
    "term": "constraint programming",
    "definition": "A programming paradigm wherein relations between variables are stated in the form of constraints. Constraints differ from the common primitives of imperative programming languages in that they do not specify a step or sequence of steps to execute, but rather the properties of a solution to be found."
  },
  {
    "term": "constructed language",
    "definition": "A language whose phonology, grammar, and vocabulary are consciously devised, instead of having developed naturally. Constructed languages may also be referred to as artificial,"
  },
  {
    "term": "container",
    "definition": "Is a class, a data structure,[76][77] or an abstract data type (ADT) whose instances are collections of other objects. In other words, they store objects in an organized way that follows specific access rules. The size of the container depends on the number of objects (elements) it contains. Underlying (inherited) implementations of various container types may vary in size and complexity, and provide flexibility in choosing the right implementation for any given scenario."
  },
  {
    "term": "continuation-passing style (CPS)",
    "definition": "A style of functional programming in which control is passed explicitly in the form of a continuation. This is contrasted with direct style, which is the usual style of programming. Gerald Jay Sussman and Guy L. Steele, Jr. coined the phrase in AI Memo 349 (1975), which sets out the first version of the Scheme programming language.[78][79]"
  },
  {
    "term": "continuous delivery (CD)",
    "definition": "Producing software in short cycles with high speed and frequency so that reliable software can be released at any time, with a simple and repeatable deployment process when deciding to deploy."
  },
  {
    "term": "continuous deployment (CD)",
    "definition": "Automatic rollout of new software functionality."
  },
  {
    "term": "continuous integration (CI)",
    "definition": "The practice of integrating source code changes frequently and ensuring that an integrated codebase is in a workable state."
  },
  {
    "term": "control flow",
    "definition": "The order in which individual statements, instructions or function calls of an imperative program are executed or evaluated. The emphasis on explicit control flow distinguishes an imperative programming language from a declarative programming language."
  },
  {
    "term": "control theory",
    "definition": "In control systems engineering is a subfield of mathematics that deals with the control of continuously operating dynamical systems in engineered processes and machines. The objective is to develop a control model for controlling such systems using a control action in an optimum manner without delay or overshoot and ensuring control stability."
  },
  {
    "term": "convolutional neural network",
    "definition": "In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural network most commonly applied to image analysis. CNNs use a variation of multilayer perceptrons designed to require minimal preprocessing.[121] They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics.[122][123]"
  },
  {
    "term": "Creative Commons (CC)",
    "definition": "An American non-profit organization devoted to expanding the range of creative works available for others to build upon legally and to share.[80] The organization has released several copyright-licenses, known as Creative Commons licenses, free of charge to the public."
  },
  {
    "term": "crossover",
    "definition": "In genetic algorithms and evolutionary computation, a genetic operator used to combine the genetic information of two parents to generate new offspring. It is one way to stochastically generate new solutions from an existing population, and analogous to the crossover that happens during sexual reproduction in biological organisms. Solutions can also be generated by cloning an existing solution, which is analogous to asexual reproduction. Newly generated solutions are typically mutated before being added to the population. D Darkforest A computer go program developed by Facebook, based on deep learning techniques using a convolutional neural network. Its updated version Darkfores2 combines the techniques of its predecessor with Monte Carlo tree search.[124][125] The MCTS effectively takes tree search methods commonly seen in computer chess programs and randomizes them.[126] With the update, the system is known as Darkfmcts3.[127]"
  },
  {
    "term": "cryptography",
    "definition": "Or cryptology, is the practice and study of techniques for secure communication in the presence of third parties called adversaries.[81] More generally, cryptography is about constructing and analyzing protocols that prevent third parties or the public from reading private messages;[82] various aspects in information security such as data confidentiality, data integrity, authentication, and non-repudiation [83] are central to modern cryptography. Modern cryptography exists at the intersection of the disciplines of mathematics, computer science, electrical engineering, communication science, and physics. Applications of cryptography include electronic commerce, chip-based payment cards, digital currencies, computer passwords, and military communications. CSV See comma-separated values."
  },
  {
    "term": "cyberbullying",
    "definition": "A form of bullying or harassment using electronic means."
  },
  {
    "term": "cyberspace",
    "definition": "Widespread, interconnected digital technology. D"
  },
  {
    "term": "daemon",
    "definition": "In multitasking computer operating systems, a daemon (/ˈdiːmən/ or /ˈdeɪmən/)[84] is a computer program that runs as a background process, rather than being under the direct control of an interactive user. Traditionally, the process names of a daemon end with the letter d, for clarification that the process is in fact a daemon, and for differentiation between a daemon and a normal computer program. For example, syslogd is a daemon that implements system logging facility, and sshd is a daemon that serves incoming SSH connections. Data"
  },
  {
    "term": "Dartmouth workshop",
    "definition": "The Dartmouth Summer Research Project on Artificial Intelligence was the name of a 1956 summer workshop now considered by many[128][129] (though not all[130]) to be the seminal event for artificial intelligence as a field."
  },
  {
    "term": "data augmentation",
    "definition": "Data augmentation in data analysis are techniques used to increase the amount of data. It helps reduce overfitting when training a learning algorithm."
  },
  {
    "term": "data center",
    "definition": "A dedicated space used to house computer systems and associated components, such as telecommunications and data storage systems. It generally includes redundant or backup components and infrastructure for power supply, data communications connections, environmental controls (e.g. air conditioning and fire suppression) and various security"
  },
  {
    "term": "data fusion",
    "definition": "The process of integrating multiple data sources to produce more consistent, accurate, and useful information than that provided by any individual data source.[131]"
  },
  {
    "term": "data integration",
    "definition": "The process of combining data residing in different sources and providing users with a unified view of them.[132] This process becomes significant in a variety of situations, which include both commercial (such as when two similar companies need to merge their databases) and scientific (combining research results from different bioinformatics repositories, for example) domains. Data integration appears with increasing frequency as the volume (that is, big data) and the need to share existing data explodes.[133] It has become the focus of extensive theoretical work, and numerous open problems remain unsolved."
  },
  {
    "term": "data mining",
    "definition": "Is a process of discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems.[86] Data mining is an interdisciplinary subfield of computer science and statistics with an overall goal to extract information (with intelligent methods) from a data set and transform the information into a comprehensible structure for further use.[86][87][88][89] Data mining is the analysis step of the \"knowledge discovery in databases\" process, or KDD.[90] Aside from the raw analysis step, it also involves database and data management aspects, data pre-processing, model and inference considerations, interestingness metrics, complexity considerations, post-processing of discovered structures, visualization, and online updating.[86]"
  },
  {
    "term": "data science",
    "definition": "An interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from data in various forms, both structured and unstructured,[91][92] similar to data mining. Data science is a \"concept to unify statistics, data analysis, machine learning and their related methods\" in order to \"understand and analyze actual phenomena\" with data.[93] It employs techniques and theories drawn from many fields within the context of mathematics, statistics, information science, and computer science."
  },
  {
    "term": "data set",
    "definition": "A collection of data. Most commonly a data set corresponds to the contents of a single database table, or a single statistical data matrix, where every column of the table represents a particular variable, and each row corresponds to a given member of the data set in question. The data set lists values for each of the variables, such as height and weight of an object, for each member of the data set. Each value is known as a datum. The data set may comprise data for one or more members, corresponding to the number of rows."
  },
  {
    "term": "data structure",
    "definition": "A data organization, management, and storage format that enables efficient access and modification.[94][95][96] More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data.[97]"
  },
  {
    "term": "data type",
    "definition": "An attribute of data which tells the compiler or interpreter how the programmer intends to use the data. Most programming languages support common data types of real, integer, and Boolean. A data type constrains the values that an expression, such as a variable or a function, might take. This data type defines the operations that can be done on the data, the meaning of the data, and the way values of that type can be stored. A type of value from which an"
  },
  {
    "term": "data warehouse (DW or DWH)",
    "definition": "A system used for reporting and data analysis.[137] DWs are central repositories of integrated data from one or more disparate sources. They store current and historical data"
  },
  {
    "term": "database",
    "definition": "An organized collection of data, generally stored and accessed electronically from a computer system. Where databases are more complex, they are often developed using formal design and modeling techniques."
  },
  {
    "term": "debugging",
    "definition": "The process of finding and resolving defects or problems within a computer program that prevent correct operation of computer software or the system as a whole. Debugging tactics can involve interactive debugging, control flow analysis, unit testing, integration testing, log file analysis, monitoring at the application or system level, memory dumps, and profiling."
  },
  {
    "term": "decision boundary",
    "definition": "In the case of backpropagation-based artificial neural networks or perceptrons, the type of decision boundary that the network can learn is determined by the number of hidden layers in the network. If it has no hidden layers, then it can only learn linear problems. If it has one hidden layer, then it can learn any continuous function on compact subsets of Rn as shown by the Universal approximation theorem, thus it can have an arbitrary decision boundary."
  },
  {
    "term": "decision support system (DSS)",
    "definition": "Aan information system that supports business or organizational decision-making activities. DSSs serve the management, operations and planning levels of an organization (usually mid and higher management) and help people make decisions about problems that may be rapidly changing and not easily specified in advance-i.e. unstructured and semi-structured decision problems. Decision support systems can be either fully computerized or human-powered, or a combination of both."
  },
  {
    "term": "decision theory",
    "definition": "The study of the reasoning underlying an agent's choices.[140] Decision theory can be broken into two branches: normative decision theory, which gives advice on how to make the best decisions given a set of uncertain beliefs and a set of values, and descriptive decision theory which analyzes how existing, possibly irrational agents actually make decisions."
  },
  {
    "term": "decision tree learning",
    "definition": "Uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modeling approaches used in statistics, data mining and machine learning."
  },
  {
    "term": "declaration",
    "definition": "In computer programming, a language construct that specifies properties of an identifier: it declares what a word (identifier) \"means\".[100] Declarations are most commonly used for functions, variables, constants, and classes, but can also be used for other entities such as enumerations and type definitions.[100] Beyond the name (the identifier itself) and the kind of entity (function, variable, etc.), declarations typically specify the data type (for variables and constants), or the type signature (for functions); types may also include dimensions, such as for arrays. A declaration is used to announce the existence of the entity to the compiler; this is important in those strongly typed languages that require functions, variables, and constants, and their types, to be specified with a declaration before use, and is used in forward declaration.[101] The term \"declaration\" is frequently contrasted with the term \"definition\",[100] but meaning and usage varies significantly between languages."
  },
  {
    "term": "declarative programming",
    "definition": "A programming paradigm-a style of building the structure and elements of computer programs-that expresses the logic of a computation without describing its control"
  },
  {
    "term": "deductive classifier",
    "definition": "A type of artificial intelligence inference engine. It takes as input a set of declarations in a frame language about a domain such as medical research or molecular biology. For example, the names of classes, sub-classes, properties, and restrictions on allowable values."
  },
  {
    "term": "Deep Blue",
    "definition": "was a chess-playing computer developed by IBM. It is known for being the first computer chess-playing system to win both a chess game and a chess match against a reigning world champion under regular time controls."
  },
  {
    "term": "deep learning",
    "definition": "A subset of machine learning that focuses on utilizing neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be either supervised, semi-supervised, or unsupervised."
  },
  {
    "term": "DeepMind Technologies",
    "definition": "A British artificial intelligence company founded in September 2010, currently owned by Alphabet Inc. The company is based in London, with research centres in Canada,[142] France,[143] and the United States. Acquired by Google in 2014, the company has created a neural network that learns how to play video games in a fashion similar to that of humans,[144] as well as a neural Turing machine,[145] or a neural network that may be able to access an external memory like a conventional Turing machine, resulting in a computer that mimics the short-term memory of the human brain.[146][147] The company made headlines in 2016 after its AlphaGo program beat human professional Go player Lee Sedol, the world champion, in a five-game match, which was the subject of a documentary film.[148] A more general program, AlphaZero, beat the most powerful programs playing Go, chess, and shogi (Japanese chess) after a few days of play against itself using"
  },
  {
    "term": "default logic",
    "definition": "A non-monotonic logic proposed by Raymond Reiter to formalize reasoning with default assumptions. Density-based spatial clustering of applications with noise (DBSCAN) A clustering algorithm proposed by Martin Ester, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu in 1996.[150]"
  },
  {
    "term": "description logic (DL)",
    "definition": "A family of formal knowledge representation languages. Many DLs are more expressive than propositional logic but less expressive than first-order logic. In contrast to the latter, the core reasoning problems for DLs are (usually) decidable, and efficient decision procedures have been designed and implemented for these problems. There are general, spatial, temporal, spatiotemporal, and fuzzy descriptions logics, and each description logic features a different balance between DL expressivity and reasoning complexity by"
  },
  {
    "term": "developmental robotics (DevRob)",
    "definition": "A scientific field which aims at studying the developmental mechanisms, architectures, and constraints that allow lifelong and open-ended learning of new skills and new knowledge in embodied machines."
  },
  {
    "term": "diagnosis",
    "definition": "Concerned with the development of algorithms and techniques that are able to determine whether the behaviour of a system is correct. If the system is not functioning correctly, the algorithm should be able to determine, as accurately as possible, which part of the system is failing, and which kind of fault it is facing. The computation is based on observations, which provide information on the current behaviour."
  },
  {
    "term": "dialogue system",
    "definition": "A computer system intended to converse with a human with a coherent structure. Dialogue systems have employed text, speech, graphics, haptics, gestures, and other modes for communication on both the input and output channel."
  },
  {
    "term": "diffusion model",
    "definition": "In machine learning, diffusion models, also known as diffusion probabilistic models or score-based generative models, are a class of latent variable models. They are Markov chains trained using variational inference.[152] The goal of diffusion models is to learn the latent structure of a dataset by modeling the way in which data points diffuse through the latent space. In computer vision, this means that a neural network is trained to denoise images blurred with Gaussian noise by learning to reverse the diffusion process.[153][154] It mainly consists of three major components: the forward process, the reverse process, and the sampling procedure.[155] Three examples of generic diffusion modeling frameworks used in computer vision are denoising diffusion probabilistic models, noise conditioned"
  },
  {
    "term": "digital data",
    "definition": "In information theory and information systems, the discrete, discontinuous representation of information or works. Numbers and letters are commonly used representations."
  },
  {
    "term": "digital signal processing (DSP)",
    "definition": "The use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations. The signals processed in this manner are a sequence of numbers that represent samples of a continuous variable in a domain such as time, space, or frequency."
  },
  {
    "term": "dimensionality reduction",
    "definition": "The process of reducing the number of random variables under consideration[157] by obtaining a set of principal variables. It can be divided into feature selection and feature"
  },
  {
    "term": "discrete event simulation (DES)",
    "definition": "A model of the operation of a system as a discrete sequence of events in time. Each event occurs at a particular instant in time and marks a change of state in the system.[102] Between consecutive events, no change in the system is assumed to occur; thus the simulation can directly jump in time from one event to the next."
  },
  {
    "term": "discrete system",
    "definition": "Any system with a countable number of states. Discrete systems may be contrasted with continuous systems, which may also be called analog systems. A final discrete system is often modeled with a directed graph and is analyzed for correctness and complexity according to computational theory. Because discrete systems have a countable number of states, they may be described in precise mathematical models. A computer is a finite-state machine that may be viewed as a discrete system. Because computers are often used to model not only other discrete systems but continuous systems as well, methods have been developed to represent real-world continuous systems as discrete systems. One such method involves sampling a continuous signal at discrete time intervals."
  },
  {
    "term": "disk storage",
    "definition": "(Also sometimes called drive storage) is a general category of storage mechanisms where data is recorded by various electronic, magnetic, optical, or mechanical changes to a surface layer of one or more rotating disks. A disk drive is a device implementing such a storage mechanism. Notable types are the hard disk drive (HDD) containing a non-removable disk, the floppy disk drive (FDD) and its removable floppy disk, and various optical disc drives (ODD) and associated optical disc media."
  },
  {
    "term": "distributed artificial intelligence (DAI)",
    "definition": "A subfield of artificial intelligence research dedicated to the development of distributed solutions for problems. DAI is closely related to and a predecessor of the field of multi-"
  },
  {
    "term": "distributed computing",
    "definition": "A field of computer science that studies distributed systems. A distributed system is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another.[103] The components interact with one another in order to achieve a common goal. Three significant characteristics of distributed systems are: concurrency of components, lack of a global clock, and independent failure of components.[103] Examples of distributed systems vary from SOA-based systems to massively multiplayer online games to peer-to-peer applications."
  },
  {
    "term": "divide and conquer algorithm",
    "definition": "An algorithm design paradigm based on multi-branched recursion. A divide-and-conquer algorithm works by recursively breaking down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem. DNS See Domain Name System."
  },
  {
    "term": "documentation",
    "definition": "Written text or illustration that accompanies computer software or is embedded in the source code. It either explains how it operates or how to use it, and may mean different things to people in different roles."
  },
  {
    "term": "domain",
    "definition": "Is the targeted subject area of a computer program. It is a term used in software engineering. Formally it represents the target subject of a specific programming project, whether narrowly or"
  },
  {
    "term": "Domain Name System (DNS)",
    "definition": "A hierarchical and decentralized naming system for computers, services, or other resources connected to the Internet or to a private network. It associates various information with domain names assigned to each of the participating entities. Most prominently, it translates more readily memorized domain names to the numerical IP addresses needed for locating and identifying computer services and devices with the underlying network protocols. By providing a worldwide, distributed directory service, the Domain Name System has been an essential component of the functionality of the Internet since 1985."
  },
  {
    "term": "double descent",
    "definition": "A phenomenon in statistics and machine learning where a model with a small number of parameters and a model with an extremely large number of parameters have a small test error, but a model whose number of parameters is about the same as the number of data points used to train the model will have a large error.[160] This phenomenon has been considered surprising, as it contradicts assumptions about overfitting in classical machine"
  },
  {
    "term": "double-precision floating-point format",
    "definition": "A computer number format. It represents a wide dynamic range of numerical values by using a floating radix point."
  },
  {
    "term": "download",
    "definition": "In computer networks, to receive data from a remote system, typically a server [105] such as a web server, an FTP server, an email server, or other similar systems. This contrasts with uploading, where data is sent to a remote server. A download is a file offered for downloading or that has been downloaded, or the process of receiving such a file. E"
  },
  {
    "term": "dropout",
    "definition": "A regularization technique for reducing overfitting in artificial neural networks by preventing complex co-adaptations on training data."
  },
  {
    "term": "dynamic epistemic logic (DEL)",
    "definition": "A logical framework dealing with knowledge and information change. Typically, DEL focuses on situations involving multiple agents and studies how their knowledge changes when events occur. E"
  },
  {
    "term": "eager learning",
    "definition": "A learning method in which the system tries to construct a general, input-independent target function during training of the system, as opposed to lazy learning, where generalization beyond the training data is delayed until a query is made to the system.[162]"
  },
  {
    "term": "early stopping",
    "definition": "A regularization technique often used when training a machine learning model with an iterative method such as gradient descent."
  },
  {
    "term": "Ebert test",
    "definition": "A test which gauges whether a computer-based synthesized voice[163][164] can tell a joke with sufficient skill to cause people to laugh.[165] It was proposed by film critic Roger Ebert at the 2011 TED conference as a challenge to software developers to have a computerized voice master the inflections, delivery, timing, and intonations of a speaking human.[163] The test is similar to the Turing test proposed by Alan Turing in 1950 as a way to gauge a computer's ability to exhibit intelligent behavior by generating performance"
  },
  {
    "term": "echo state network (ESN)",
    "definition": "A recurrent neural network with a sparsely connected hidden layer (with typically 1% connectivity). The connectivity and weights of hidden neurons are fixed and randomly assigned. The weights of output neurons can be learned so that the network can (re)produce specific temporal patterns. The main interest of this network is that although its behaviour is non-linear, the only weights that are modified during training are for the synapses that connect the hidden neurons to output neurons. Thus, the error function is quadratic with respect to the parameter vector and can be differentiated easily to a linear"
  },
  {
    "term": "edge device",
    "definition": "A device which provides an entry point into enterprise or service provider core networks. Examples include routers, routing switches, integrated access devices (IADs), multiplexers, and a variety of metropolitan area network (MAN) and wide area network (WAN) access devices. Edge devices also provide connections into carrier and service provider networks. An edge device that connects a local area network to a high speed switch or backbone (such as an ATM switch) may be called an edge concentrator."
  },
  {
    "term": "embodied agent",
    "definition": "An intelligent agent that interacts with the environment through a physical body within that environment. Agents that are represented graphically with a body, for example a human or a cartoon animal, are also called embodied agents, although they have only virtual, not"
  },
  {
    "term": "embodied cognitive science",
    "definition": "An interdisciplinary field of research, the aim of which is to explain the mechanisms underlying intelligent behavior. It comprises three main methodologies: 1) the modeling of psychological and biological systems in a holistic manner that considers the mind and body as a single entity, 2) the formation of a common set of general principles of intelligent behavior, and 3) the experimental use of robotic agents in controlled environments."
  },
  {
    "term": "emulator",
    "definition": "Hardware or software that enables one computer system (called the host) to behave like another computer system."
  },
  {
    "term": "encryption",
    "definition": "In cryptography, encryption is the process of encoding information. This process converts the original representation of the information, known as plaintext, into an alternative form known as ciphertext. Ideally, only authorized parties can decipher a ciphertext back to plaintext and access the original information. Encryption does not itself prevent interference but denies the intelligible content to a would-be interceptor. For technical reasons, an encryption scheme usually uses a pseudo-random encryption key generated by an algorithm. It is possible to decrypt the message without possessing the key, but, for a well-designed encryption scheme, considerable computational resources and skills are required. An authorized recipient can easily decrypt the message with the key provided by the originator to recipients but not to unauthorized users. Historically, various forms of encryption have been used to aid in cryptography. Early encryption techniques were often utilized in military messaging. Since then, new techniques have emerged and become commonplace in all areas of modern computing.[106] Modern encryption schemes utilize the concepts of public-key and symmetric- key.[106] Modern encryption techniques ensure security because modern computers are inefficient at cracking the encryption."
  },
  {
    "term": "ensemble learning",
    "definition": "The use of multiple machine learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone.[170][171][172]"
  },
  {
    "term": "epoch",
    "definition": "In machine learning, particularly in the creation of artificial neural networks, an epoch is training the model for one cycle through the full training dataset. Small models are typically trained for as many epochs as it takes to reach the best performance on the validation dataset. The largest models may train for only one epoch."
  },
  {
    "term": "error-driven learning",
    "definition": "A sub-area of machine learning concerned with how an agent ought to take actions in an environment so as to minimize some error feedback. It is a type of reinforcement learning."
  },
  {
    "term": "ethics of artificial intelligence",
    "definition": "The part of the ethics of technology specific to artificial intelligence."
  },
  {
    "term": "event",
    "definition": "An action or occurrence recognized by software, often originating asynchronously from the external environment, that may be handled by the software. Because an event is an entity which encapsulates the action and the contextual variables triggering the action, the acrostic mnemonic \"Execution Variable Encapsulating Named Trigger\" is often used to clarify the concept."
  },
  {
    "term": "event-driven programming",
    "definition": "A programming paradigm in which the flow of the program is determined by events such as user actions (mouse clicks, key presses), sensor outputs, or messages from other programs or threads. Event-driven programming is the dominant paradigm used in graphical user interfaces and other applications (e.g. JavaScript web applications) that are centered on performing certain actions in response to user input. This is also true of programming for device drivers (e.g. P in USB device driver stacks[107])."
  },
  {
    "term": "evolutionary algorithm (EA)",
    "definition": "A subset of evolutionary computation,[173] a generic population-based metaheuristic optimization algorithm. An EA uses mechanisms inspired by biological evolution, such as reproduction, mutation, recombination, and selection. Candidate solutions to the optimization problem play the role of individuals in a population, and the fitness function determines the quality of the solutions (see also loss function). Evolution of the population then takes place after the repeated application of the above operators."
  },
  {
    "term": "evolutionary computation",
    "definition": "A family of algorithms for global optimization inspired by biological evolution, and the subfield of artificial intelligence and soft computing studying these algorithms. In technical terms, they are a family of population-based trial and error problem solvers with a metaheuristic or stochastic optimization character."
  },
  {
    "term": "evolutionary computing",
    "definition": "A family of algorithms for global optimization inspired by biological evolution, and the subfield of artificial intelligence and soft computing studying these algorithms. In technical terms, they are a family of population-based trial-and-error problem-solvers with a metaheuristic or stochastic optimization character."
  },
  {
    "term": "evolving classification function (ECF)",
    "definition": "Evolving classification functions are used for classifying and clustering in the field of machine learning and artificial intelligence, typically employed for data stream mining tasks in dynamic and changing environments."
  },
  {
    "term": "exception handling",
    "definition": "The process of responding to the occurrence, during computation, of exceptions – anomalous or exceptional conditions requiring special processing – often disrupting the normal flow of program execution. It is provided by specialized programming language constructs, computer hardware mechanisms like interrupts, or operating system IPC facilities like signals."
  },
  {
    "term": "executable",
    "definition": "Causes a computer \"to perform indicated tasks according to encoded instructions,\"[108] as opposed to a data file that must be parsed by a program to be meaningful. The exact interpretation depends upon the use - while \"instructions\" is traditionally taken to mean machine code instructions for a physical CPU, in some contexts a file containing bytecode or scripting language instructions may also be considered executable."
  },
  {
    "term": "execution",
    "definition": "In computer and software engineering is the process by which a computer or virtual machine executes the instructions of a computer program. Each instruction of a program is a description of a particular action which to be carried out in order for a specific problem to be solved; as instructions of a program and therefore the actions they describe are being carried out by an executing machine, specific effects are produced in accordance to the semantics of the instructions being executed."
  },
  {
    "term": "Existence detection",
    "definition": "An existence check before reading a file can catch and/or prevent a fatal error."
  },
  {
    "term": "existential risk",
    "definition": "The hypothesis that substantial progress in artificial general intelligence (AGI) could someday result in human extinction or some other unrecoverable global"
  },
  {
    "term": "expert system",
    "definition": "A computer system that emulates the decision-making ability of a human expert.[177] Expert systems are designed to solve complex problems by reasoning through bodies of knowledge, represented mainly as if–then rules rather than through conventional"
  },
  {
    "term": "expression",
    "definition": "In a programming language, a combination of one or more constants, variables, operators, and functions that the programming language interprets (according to its particular rules of precedence and of association) and computes to produce (\"to return\", in a stateful environment) another value. This process, as for mathematical expressions, is called evaluation. F"
  },
  {
    "term": "fast-and-frugal trees",
    "definition": "A type of classification tree. Fast-and-frugal trees can be used as decision-making tools which operate as lexicographic classifiers, and, if required, associate an action (decision)"
  },
  {
    "term": "fault-tolerant computer system",
    "definition": "A system designed around the concept of fault tolerance. In essence, they must be able to continue working to a level of satisfaction in the presence of errors or breakdowns."
  },
  {
    "term": "feasibility study",
    "definition": "An investigation which aims to objectively and rationally uncover the strengths and weaknesses of an existing business or proposed venture, opportunities and threats present in the natural environment, the resources required to carry through, and ultimately the prospects for success.[109][110] In its simplest terms, the two criteria to judge feasibility are cost required and"
  },
  {
    "term": "feature",
    "definition": "An individual measurable property or characteristic of a phenomenon.[180] In computer vision and image processing, a feature is a piece of information about the content of an image; typically about whether a certain region of the image has certain properties. Features may be specific structures in an image (such as points, edges, or objects), or the result of a general neighborhood operation or feature detection applied to the image."
  },
  {
    "term": "feature extraction",
    "definition": "In machine learning, pattern recognition, and image processing, feature extraction starts from an initial set of measured data and builds derived values (features) intended to be informative and non-redundant, facilitating the subsequent learning and generalization steps, and in some cases leading to better human interpretations."
  },
  {
    "term": "feature learning",
    "definition": "In machine learning, feature learning or representation learning[181] is a set of techniques that allows a system to automatically discover the representations needed for feature detection or classification from raw data. This replaces manual feature engineering and allows a machine to both learn the features and use them to perform a specific task."
  },
  {
    "term": "feature selection",
    "definition": "In machine learning and statistics, feature selection, also known as variable selection, attribute selection or variable subset selection, is the process of selecting a subset of relevant features (variables, predictors) for use in model construction."
  },
  {
    "term": "federated learning",
    "definition": "A machine learning technique that allows for training models on multiple devices with decentralized data, thus helping preserve the privacy of individual users and their data."
  },
  {
    "term": "field",
    "definition": "Data that has several parts, known as a record, can be divided into fields. Relational databases arrange data as sets of database records, so called rows. Each record consists of several fields; the fields of all records form the columns. Examples of fields: name, gender, hair colour."
  },
  {
    "term": "filename extension",
    "definition": "An identifier specified as a suffix to the name of a computer file. The extension indicates a characteristic of the file contents or its intended use."
  },
  {
    "term": "filter (software)",
    "definition": "A computer program or subroutine to process a stream, producing another stream. While a single filter can be used individually, they are frequently strung together to form a pipeline."
  },
  {
    "term": "first-order logic",
    "definition": "A collection of formal systems used in mathematics, philosophy, linguistics, and computer science. First-order logic uses quantified variables over non-logical objects and allows the use of sentences that contain variables, so that rather than propositions such as Socrates is a man one can have expressions in the form \"there exists X such that X is Socrates and X is a man\" and there exists is a quantifier while X is a variable.[182] This distinguishes it from propositional logic, which does not use quantifiers or relations.[183]"
  },
  {
    "term": "floating-point arithmetic",
    "definition": "In computing, floating-point arithmetic (FP) is arithmetic using formulaic representation of real numbers as an approximation to support a trade-off between range and precision. For this reason, floating-point computation is often found in systems which include very small and very large real numbers, which require fast processing times. A number is, in general, represented approximately to a fixed number of significant digits (the significand) and scaled using an exponent in some fixed base; the base for the scaling is normally two, ten, or sixteen. A number"
  },
  {
    "term": "fluent",
    "definition": "A condition that can change over time. In logical approaches to reasoning about actions, fluents can be represented in first-order logic by predicates having an argument that depends on time."
  },
  {
    "term": "for loop",
    "definition": "A control flow statement for specifying iteration, which allows code to be executed repeatedly. Various keywords are used to specify this statement: descendants of ALGOL use \"for\", while descendants of Fortran use \"do\". There are also other possibilities, e.g. COBOL uses \"PERFORM VARYING\"."
  },
  {
    "term": "for recompilation.[137]",
    "definition": "K"
  },
  {
    "term": "formal language",
    "definition": "A set of words whose letters are taken from an alphabet and are well-formed according to a specific set of rules."
  },
  {
    "term": "formal methods",
    "definition": "A set of mathematically based techniques for the specification, development, and verification of software and hardware systems.[112] The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a"
  },
  {
    "term": "formal verification",
    "definition": "The act of proving or disproving the correctness of intended algorithms underlying a system with respect to a certain formal specification or property, using formal methods of"
  },
  {
    "term": "forward chaining",
    "definition": "One of the two main methods of reasoning when using an inference engine and can be described logically as repeated application of modus ponens. Forward chaining is a popular implementation strategy for expert systems, businesses and production rule systems. The opposite of forward chaining is backward chaining. Forward chaining starts with the available data and uses inference rules to extract more data (from an end user, for example) until a goal is reached. An inference engine using forward chaining searches the inference rules until it finds one where the antecedent (If clause) is known to be true. When such a rule is found, the engine can conclude, or infer, the consequent (Then clause), resulting in the addition of new information to its data.[184]"
  },
  {
    "term": "frame",
    "definition": "An artificial intelligence data structure used to divide knowledge into substructures by representing \"stereotyped situations\". Frames are the primary data structure used in artificial intelligence frame language."
  },
  {
    "term": "frame language",
    "definition": "A technology used for knowledge representation in artificial intelligence. Frames are stored as ontologies of sets and subsets of the frame concepts. They are similar to class hierarchies in object-oriented languages although their fundamental design goals are different. Frames are focused on explicit and intuitive representation of knowledge whereas objects focus on encapsulation and information hiding. Frames originated in AI research and objects primarily in software engineering. However, in practice the techniques and capabilities of frame and object-oriented languages overlap significantly."
  },
  {
    "term": "frame problem",
    "definition": "The problem of finding adequate collections of axioms for a viable description of a robot"
  },
  {
    "term": "friendly artificial intelligence",
    "definition": "A hypothetical artificial general intelligence (AGI) that would have a positive effect on humanity. It is a part of the ethics of artificial intelligence and is closely related to machine ethics. While machine ethics is concerned with how an artificially intelligent agent should behave, friendly artificial intelligence research is focused on how to practically bring about this behaviour and ensuring it is adequately constrained."
  },
  {
    "term": "functional programming",
    "definition": "A programming paradigm-a style of building the structure and elements of computer programs–that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. It is a declarative programming paradigm in that programming is done with expressions or declarations[115] instead of statements. G"
  },
  {
    "term": "futures studies",
    "definition": "The study of postulating possible, probable, and preferable futures and the worldviews"
  },
  {
    "term": "fuzzy control system",
    "definition": "A control system based on fuzzy logic-a mathematical system that analyzes analog input values in terms of logical variables that take on continuous values between 0 and 1, in contrast to classical or digital logic, which operates on discrete values of either 1 or 0 (true"
  },
  {
    "term": "fuzzy logic",
    "definition": "A simple form for the many-valued logic, in which the truth values of variables may have any degree of \"Truthfulness\" that can be represented by any real number in the range between 0 (as in Completely False) and 1 (as in Completely True) inclusive. Consequently, It is employed to handle the concept of partial truth, where the truth value may range between completely true and completely false. In contrast to Boolean logic, where the truth values of variables may have the integer values 0 or 1 only."
  },
  {
    "term": "fuzzy rule",
    "definition": "A rule used within fuzzy logic systems to infer an output based on input variables."
  },
  {
    "term": "fuzzy set",
    "definition": "In classical set theory, the membership of elements in a set is assessed in binary terms according to a bivalent condition - an element either belongs or does not belong to the set. By contrast, fuzzy set theory permits the gradual assessment of the membership of elements in a set; this is described with the aid of a membership function valued in the real unit interval [0, 1]. Fuzzy sets generalize classical sets, since the indicator functions (aka characteristic functions) of classical sets are special cases of the membership functions of fuzzy sets, if the latter only take values 0 or 1.[189] In fuzzy set theory, classical bivalent sets are usually called crisp sets. The fuzzy set theory can be used in a wide range of domains in which information is incomplete or imprecise, such as"
  },
  {
    "term": "game theory",
    "definition": "The study of mathematical models of strategic interaction between rational decision-makers.[116] It has applications in all fields of social science, as well as in logic and computer science. Originally, it addressed zero-sum games, in which each participant's gains or losses are exactly balanced by those of the other participants. Today, game theory applies to a wide range of behavioral relations, and is now an umbrella term for the science of logical decision making in humans, animals, and computers."
  },
  {
    "term": "garbage in, garbage out (GIGO)",
    "definition": "A term used to describe the concept that flawed or nonsense input data produces nonsense output or \"garbage\". It can also refer to the unforgiving nature of programming, in which a poorly written program might produce nonsensical behavior."
  },
  {
    "term": "general game playing (GGP)",
    "definition": "General game playing is the design of artificial intelligence programs to be able to run and"
  },
  {
    "term": "generalization",
    "definition": "The concept that humans, other animals, and artificial neural networks use past learning in present situations of learning if the conditions in the situations are regarded as"
  },
  {
    "term": "generalization error",
    "definition": "For supervised learning applications in machine learning and statistical learning theory, generalization error[196] (also known as the out-of-sample error[197] or the risk) is a measure of how accurately a learning algorithm is able to predict outcomes for previously unseen data."
  },
  {
    "term": "generative adversarial network (GAN)",
    "definition": "A class of machine learning systems. Two neural networks contest with each other in a zero-sum game framework."
  },
  {
    "term": "generative artificial intelligence",
    "definition": "Generative artificial intelligence is artificial intelligence capable of generating text, images, or other media in response to prompts.[198][199] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics, typically using transformer-based deep neural networks.[200][201]"
  },
  {
    "term": "generative pretrained transformer (GPT)",
    "definition": "A large language model based on the transformer architecture that generates text. It is first pretrained to predict the next token in texts (a token is typically a word, subword, or punctuation). After their pretraining, GPT models can generate human-like text by repeatedly predicting the token that they would expect to follow. GPT models are usually also fine-tuned, for example with reinforcement learning from human feedback to reduce hallucination or harmful behaviour, or to format the output in a conversationnal format.[202]"
  },
  {
    "term": "genetic algorithm (GA)",
    "definition": "A metaheuristic inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms (EA). Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on bio-inspired"
  },
  {
    "term": "genetic operator",
    "definition": "An operator used in genetic algorithms to guide the algorithm towards a solution to a given problem. There are three main types of operators (mutation, crossover and selection), which must work in conjunction with one another in order for the algorithm to be successful."
  },
  {
    "term": "gigabyte",
    "definition": "A multiple of the unit byte for digital information. The prefix giga means 109 in the International System of Units (SI). Therefore, one gigabyte is 1 000 000 000 bytes. The unit symbol for the gigabyte is GB."
  },
  {
    "term": "global variable",
    "definition": "In computer programming, a variable with global scope, meaning that it is visible (hence accessible) throughout the program, unless shadowed. The set of all global variables is known as the global environment or global state. In compiled languages, global variables are generally static variables, whose extent (lifetime) is the entire runtime of the program, though in interpreted languages (including command-line interpreters), global variables are generally dynamically allocated when declared, since they are not known ahead of time."
  },
  {
    "term": "glowworm swarm optimization",
    "definition": "A swarm intelligence optimization algorithm based on the behaviour of glowworms (also known as fireflies or lightning bugs)."
  },
  {
    "term": "gradient boosting",
    "definition": "A machine learning technique based on boosting in a functional space, where the target is pseudo-residuals instead of residuals as in traditional boosting."
  },
  {
    "term": "graph (abstract data type)",
    "definition": "In computer science, a graph is an abstract data type that is meant to implement the undirected graph and directed graph concepts from mathematics; specifically, the field of graph theory."
  },
  {
    "term": "graph (discrete mathematics)",
    "definition": "In mathematics, and more specifically in graph theory, a graph is a structure amounting to a set of objects in which some pairs of the objects are in some sense \"related\". The objects correspond to mathematical abstractions called vertices (also called nodes or points) and each of the related pairs of vertices is called an edge (also called an arc or"
  },
  {
    "term": "graph database (GDB)",
    "definition": "A database that uses graph structures for semantic queries with nodes, edges, and properties to represent and store data. A key concept of the system is the graph (or edge or relationship), which directly relates data items in the store a collection of nodes of data and edges representing the relationships between the nodes. The relationships allow data in the store to be linked together directly, and in many cases retrieved with one operation. Graph databases hold the relationships between data as a priority. Querying relationships within a graph database is fast because they are perpetually stored within the database itself. Relationships can be intuitively visualized using graph databases, making it useful"
  },
  {
    "term": "graph theory",
    "definition": "In mathematics, the study of graphs, which are mathematical structures used to model pairwise relations between objects. A graph in this context is made up of vertices (also called nodes or points) which are connected by edges (also called links or lines). A distinction is made between undirected graphs, where edges link two vertices symmetrically, and directed graphs, where edges link two vertices asymmetrically. H"
  },
  {
    "term": "graph traversal",
    "definition": "The process of visiting (checking and/or updating) each vertex in a graph. Such traversals are classified by the order in which the vertices are visited. Tree traversal is a special case of graph traversal. H"
  },
  {
    "term": "hallucination",
    "definition": "A response generated by AI that contains false or misleading information presented as fact."
  },
  {
    "term": "handle",
    "definition": "In computer programming, a handle is an abstract reference to a resource that is used when application software references blocks of memory or objects that are managed by another system like a database or an operating system."
  },
  {
    "term": "hard problem",
    "definition": "Computational complexity theory focuses on classifying computational problems according to their inherent difficulty, and relating these classes to each other. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm."
  },
  {
    "term": "hash function",
    "definition": "Any function that can be used to map data of arbitrary size to data of a fixed size. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes. Hash functions are often used in combination with a hash table, a common data structure used in computer software for rapid data lookup. Hash functions accelerate table or database lookup by detecting duplicated records in a large file."
  },
  {
    "term": "hash table",
    "definition": "In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index into an array of buckets or slots, from which the desired value can be found."
  },
  {
    "term": "heap",
    "definition": "A specialized tree-based data structure which is essentially an almost complete[117] tree that satisfies the heap property: if P is a parent node of C, then the key (the value) of P is either greater than or equal to (in a max heap) or less than or equal to (in a min heap) the key of C.[118] The node at the \"top\" of the heap (with no parents) is called the root node."
  },
  {
    "term": "heapsort",
    "definition": "A comparison-based sorting algorithm. Heapsort can be thought of as an improved selection sort: like that algorithm, it divides its input into a sorted and an unsorted region, and it iteratively shrinks the unsorted region by extracting the largest element and moving that to the sorted region. The improvement consists of the use of a heap data structure rather than a linear-time"
  },
  {
    "term": "heuristic",
    "definition": "A technique designed for solving a problem more quickly when classic methods are too slow, or for finding an approximate solution when classic methods fail to find any exact solution. This is achieved by trading optimality, completeness, accuracy, or precision for speed. In a way, it can be considered a shortcut. A heuristic function, also called simply a heuristic, is a function that ranks alternatives in search algorithms at each branching step based on available information to decide which branch to follow. For example, it may"
  },
  {
    "term": "hidden layer",
    "definition": "A layer of neurons in an artificial neural network that is neither an input layer nor an output layer."
  },
  {
    "term": "human-computer interaction (HCI)",
    "definition": "Researches the design and use of computer technology, focused on the interfaces between people (users) and computers. Researchers in the field of HCI both observe the ways in which humans interact with computers and design technologies that let humans interact with computers in novel ways. As a field of research, human–computer interaction is situated at the intersection of computer science, behavioral sciences, design, media studies, and several other fields of study. I"
  },
  {
    "term": "hyper-heuristic",
    "definition": "A heuristic search method that seeks to automate the process of selecting, combining, generating, or adapting several simpler heuristics (or components of such heuristics) to efficiently solve computational search problems, often by the incorporation of machine learning techniques. One of the motivations for studying hyper-heuristics is to build systems which can handle classes of problems rather than solving just one"
  },
  {
    "term": "hyperparameter",
    "definition": "A parameter that can be set in order to define any configurable part of a machine learning model's learning process."
  },
  {
    "term": "hyperparameter optimization",
    "definition": "The process of choosing a set of optimal hyperparameters for a learning algorithm."
  },
  {
    "term": "hyperplane",
    "definition": "A decision boundary in machine learning classifiers that partitions the input space into two or more sections, with each section corresponding to a unique class label. I"
  },
  {
    "term": "identifier",
    "definition": "In computer languages, identifiers are tokens (also called symbols) which name language entities. Some of the kinds of entities an identifier might denote include variables, types, labels, subroutines, and packages. IDE Integrated development environment."
  },
  {
    "term": "IEEE Computational Intelligence Society",
    "definition": "A professional society of the Institute of Electrical and Electronics Engineers (IEEE) focussing on \"the theory, design, application, and development of biologically and linguistically motivated computational paradigms emphasizing neural networks, connectionist systems, genetic algorithms, evolutionary programming, fuzzy systems, and hybrid intelligent systems in which these paradigms are contained\".[211]"
  },
  {
    "term": "imperative programming",
    "definition": "A programming paradigm that uses statements that change a program's state. In much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. Imperative programming focuses on describing how a program operates."
  },
  {
    "term": "in one single place[138]",
    "definition": "Datalog A declarative logic programming language that syntactically is a subset of Prolog. It is often used as a query language for deductive databases. In recent years, Datalog has found new application in data integration, information extraction, networking, program"
  },
  {
    "term": "incremental build model",
    "definition": "A method of software development where the product is designed, implemented and tested incrementally (a little more is added each time) until the product is finished. It involves both development and maintenance. The product is defined as finished when it satisfies all of its requirements. This model combines the elements of the waterfall model with the iterative philosophy of prototyping."
  },
  {
    "term": "incremental learning",
    "definition": "A method of machine learning, in which input data is continuously used to extend the existing model's knowledge i.e. to further train the model. It represents a dynamic technique of supervised and unsupervised learning that can be applied when training data becomes available gradually over time or its size is out of system memory limits. Algorithms that can facilitate incremental learning are known as incremental machine learning algorithms."
  },
  {
    "term": "inference engine",
    "definition": "A component of the system that applies logical rules to the knowledge base to deduce new information."
  },
  {
    "term": "information integration (II)",
    "definition": "The merging of information from heterogeneous sources with differing conceptual, contextual and typographical representations. It is used in data mining and consolidation of data from unstructured or semi-structured resources. Typically, information integration refers to textual representations of knowledge but is sometimes applied to rich-media content. Information fusion, which is a related term, involves the combination of information into a new set of information towards reducing redundancy and"
  },
  {
    "term": "Information Processing Language (IPL)",
    "definition": "A programming language that includes features intended to help with programs that perform simple problem solving actions such as lists, dynamic memory allocation, data types, recursion, functions as arguments, generators, and cooperative multitasking. IPL invented the concept of list processing, albeit in an assembly-language style."
  },
  {
    "term": "information space analysis",
    "definition": "A deterministic method, enhanced by machine intelligence, for locating and assessing resources for team-centric efforts."
  },
  {
    "term": "inheritance",
    "definition": "In object-oriented programming, the mechanism of basing an object or class upon another object (prototype-based inheritance) or class (class-based inheritance), retaining similar implementation. Also defined as deriving new classes (sub classes) from existing ones (super class or base class) and forming them into a hierarchy of classes."
  },
  {
    "term": "input/output (I/O)",
    "definition": "The communication between an information processing system, such as a computer, and the outside world, possibly a human or another information processing system. Inputs are the signals or data received by the system and outputs are the signals or data sent from it. The term can also be used as part of an action; to \"perform I/O\" is to perform an input or output operation."
  },
  {
    "term": "insertion sort",
    "definition": "A simple sorting algorithm that builds the final sorted array (or list) one item at a time."
  },
  {
    "term": "instruction cycle",
    "definition": "The cycle which the central processing unit (CPU) follows from boot-up until the computer has shut down in order to process instructions. It is composed of three main stages: the fetch stage, the decode stage, and the execute stage."
  },
  {
    "term": "integer",
    "definition": "A datum of integral data type, a data type that represents some range of mathematical integers. Integral data types may be of different sizes and may or may not be allowed to contain negative values. Integers are commonly represented in a computer as a group of binary digits (bits). The size of the grouping varies so the set of integer sizes available varies between different types of computers. Computer hardware, including virtual machines, nearly always provide a way to represent a processor register or memory address as an integer."
  },
  {
    "term": "integrated development environment (IDE)",
    "definition": "A software application that provides comprehensive facilities to computer programmers for software development. An IDE normally consists of at least a source code editor, build automation tools, and a debugger."
  },
  {
    "term": "integration testing",
    "definition": "(sometimes called integration and testing, abbreviated I&T) is the phase in software testing in which individual software modules are combined and tested as a group. Integration testing is conducted to evaluate the compliance of a system or component with specified functional requirements.[120] It occurs after unit testing and before validation testing. Integration testing takes as its input modules that have been unit tested, groups them in larger aggregates, applies tests defined in an integration test plan to those aggregates, and delivers as its output the"
  },
  {
    "term": "intellectual property (IP)",
    "definition": "A category of legal property that includes intangible creations of the human intellect.[122][123] There are many types of intellectual property, and some countries recognize more than others.[124][125][126][127][128] The most well-known types are copyrights, patents, trademarks, and trade secrets."
  },
  {
    "term": "intelligence amplification (IA)",
    "definition": "The effective use of information technology in augmenting human intelligence."
  },
  {
    "term": "intelligence explosion",
    "definition": "A possible outcome of humanity building artificial general intelligence (AGI). AGI would be capable of recursive self-improvement leading to rapid emergence of ASI (artificial superintelligence), the limits of which are unknown, at the time of the technological singularity."
  },
  {
    "term": "intelligent agent",
    "definition": "In artificial intelligence, an intelligent agent (IA) refers to an autonomous entity which acts, directing its activity towards achieving goals (i.e. it is an agent), upon an environment using observation through sensors and consequent actuators (i.e. it is intelligent).[129] Intelligent agents may also learn or use knowledge to achieve their goals. They may be very simple or very complex. A reflex machine, such as a thermostat, is considered an example of an intelligent"
  },
  {
    "term": "intelligent agent (IA)",
    "definition": "An autonomous entity which acts, directing its activity towards achieving goals (i.e. it is an agent), upon an environment using observation through sensors and consequent actuators (i.e. it is intelligent). Intelligent agents may also learn or use knowledge to achieve their goals. They may be very simple or very complex."
  },
  {
    "term": "intelligent control",
    "definition": "A class of control techniques that use various artificial intelligence computing approaches like neural networks, Bayesian probability, fuzzy logic, machine learning, reinforcement learning, evolutionary computation and genetic algorithms.[212]"
  },
  {
    "term": "intelligent personal assistant",
    "definition": "A software agent that can perform tasks or services for an individual based on verbal commands. Sometimes the term \"chatbot\" is used to refer to virtual assistants generally or specifically accessed by online chat (or in some cases online chat programs that are exclusively for entertainment purposes). Some virtual assistants are able to interpret human speech and respond via synthesized voices. Users can ask their assistants questions, control home automation devices and media playback via voice, and manage other basic tasks such as email, to-do lists, and calendars with verbal commands.[213]"
  },
  {
    "term": "interface",
    "definition": "A shared boundary across which two or more separate components of a computer system exchange information. The exchange can be between software, computer hardware, peripheral devices, humans, and combinations of these.[131] Some computer hardware devices, such as a touchscreen, can both send and receive data through the interface, while others such as a mouse or microphone may only provide an interface to send data to a given system.[132]"
  },
  {
    "term": "internal documentation",
    "definition": "Computer software is said to have Internal Documentation if the notes on how and why various parts of code operate is included within the source code as comments. It is often combined with meaningful variable names with the intention of providing potential future programmers a means of understanding the workings of the code. This contrasts with external documentation, where programmers keep their notes and explanations in a separate document."
  },
  {
    "term": "internet",
    "definition": "The global system of interconnected computer networks that use the Internet protocol suite (TCP/IP) to link devices worldwide. It is a network of networks that consists of private, public, academic, business, and government networks of local to global scope, linked by a broad array of electronic, wireless, and optical networking technologies."
  },
  {
    "term": "internet bot",
    "definition": "A software application that runs automated tasks (scripts) over the Internet.[133] Typically, bots perform tasks that are both simple and structurally repetitive, at a much higher rate than would be possible for a human alone. The largest use of bots is in web spidering (web crawler), in which an automated script fetches, analyzes and files information from web servers at many times the speed of a human."
  },
  {
    "term": "interpretation",
    "definition": "An assignment of meaning to the symbols of a formal language. Many formal languages used in mathematics, logic, and theoretical computer science are defined in solely syntactic terms, and as such do not have any meaning until they are given some interpretation. The general study of interpretations of formal languages is called formal semantics."
  },
  {
    "term": "interpreter",
    "definition": "A computer program that directly executes instructions written in a programming or scripting language, without requiring them to have been previously compiled into a machine language program."
  },
  {
    "term": "intrinsic motivation",
    "definition": "An intelligent agent is intrinsically motivated to act if the information content alone, of the experience resulting from the action, is the motivating factor. Information content in this context is measured in the information theory sense as quantifying uncertainty. A typical intrinsic motivation is to search for unusual (surprising) situations, in contrast to a typical extrinsic motivation such as the search for food. Intrinsically motivated artificial agents"
  },
  {
    "term": "invariant",
    "definition": "One can encounter invariants that can be relied upon to be true during the execution of a program, or during some portion of it. It is a logical assertion that is always held to be true during a certain phase of execution. For example, a loop invariant is a condition that is true at the beginning and the end of every execution of a loop."
  },
  {
    "term": "issue tree",
    "definition": "A graphical breakdown of a question that dissects it into its different components vertically and that progresses into details as it reads to the right.[215]: 47 Issue trees are useful in problem solving to identify the root causes of a problem as well as to identify its potential solutions. They also provide a reference point to see how each piece fits into the whole"
  },
  {
    "term": "iteration",
    "definition": "Is the repetition of a process in order to generate an outcome. The sequence will approach some end point or end value. Each repetition of the process is a single iteration, and the outcome of each iteration is then the starting point of the next iteration. In mathematics and computer science, iteration (along with the related technique of recursion) is a standard element of algorithms. J Java A general-purpose programming language that is class-based, object-oriented [134](although not a pure OO language[135]), and designed to have as few implementation dependencies as possible. It is intended to let application developers \"write once, run anywhere\" (WORA),[136] meaning that compiled Java code can run on all platforms that support Java without the need"
  },
  {
    "term": "junction tree algorithm",
    "definition": "A method used in machine learning to extract marginalization in general graphs. In essence, it entails performing belief propagation on a modified graph called a junction tree. The graph is called a tree because it branches into different sections of data; nodes"
  },
  {
    "term": "k-means clustering",
    "definition": "A method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster. L"
  },
  {
    "term": "k-nearest neighbors",
    "definition": "A non-parametric supervised learning method first developed by Evelyn Fix and Joseph Hodges in 1951,[221] and later expanded by Thomas Cover.[217] It is used for classification and regression."
  },
  {
    "term": "kernel",
    "definition": "The first section of an operating system to load into memory. As the center of the operating system, the kernel needs to be small, efficient, and loaded into a protected area in the memory so that it cannot be overwritten. It may be responsible for such essential tasks as disk drive management, file management, memory management, process management, etc. L"
  },
  {
    "term": "kernel method",
    "definition": "In machine learning, kernel methods are a class of algorithms for pattern analysis, whose best known member is the support vector machine (SVM). The general task of pattern analysis is to find and study general types of relations (e.g., cluster analysis, rankings, principal components, correlations, classifications) in datasets. KL-ONE A well-known knowledge representation system in the tradition of semantic networks and frames; that is, it is a frame language. The system is an attempt to overcome semantic indistinctness in semantic network representations and to explicitly represent conceptual information as a structured inheritance network.[218][219][220]"
  },
  {
    "term": "knowledge acquisition",
    "definition": "The process used to define the rules and ontologies required for a knowledge-based system. The phrase was first used in conjunction with expert systems to describe the initial tasks associated with developing an expert system, namely finding and interviewing domain experts and capturing their knowledge via rules, objects, and frame-based ontologies."
  },
  {
    "term": "knowledge distillation",
    "definition": "The process of transferring knowledge from a large machine learning model to a smaller one."
  },
  {
    "term": "knowledge engineering (KE)",
    "definition": "All technical, scientific, and social aspects involved in building, maintaining, and using knowledge-based systems."
  },
  {
    "term": "knowledge extraction",
    "definition": "The creation of knowledge from structured (relational databases, XML) and unstructured (text, documents, images) sources. The resulting knowledge needs to be in a machine- readable and machine-interpretable format and must represent knowledge in a manner that facilitates inferencing. Although it is methodically similar to information extraction and ETL, the main criterion is that the extraction result goes beyond the creation of structured information or the transformation into a relational schema. It requires either the reuse of existing formal knowledge (reusing identifiers or ontologies) or the generation of a schema based on the source data."
  },
  {
    "term": "knowledge Interchange Format (KIF)",
    "definition": "A computer language designed to enable systems to share and reuse information from knowledge-based systems. KIF is similar to frame languages such as KL-ONE and LOOM but unlike such language its primary role is not intended as a framework for the expression or use of knowledge but rather for the interchange of knowledge between systems. The designers of KIF likened it to PostScript. PostScript was not designed primarily as a language to store and manipulate documents but rather as an interchange format for systems and devices to share documents. In the same way KIF is meant to facilitate sharing of knowledge across different systems that use different languages, formalisms, platforms, etc."
  },
  {
    "term": "knowledge representation and reasoning (KR² or KR&R)",
    "definition": "The field of artificial intelligence dedicated to representing information about the world in a form that a computer system can utilize to solve complex tasks such as diagnosing a medical condition or having a dialog in a natural language. Knowledge representation incorporates findings from psychology[222] about how humans solve problems and represent knowledge in order to design formalisms that will make complex systems easier to design and build. Knowledge representation and reasoning also incorporates findings from logic to automate various kinds of reasoning, such as the application of rules or the relations of sets and subsets.[223] Examples of knowledge representation formalisms include semantic nets, systems architecture, frames, rules, and ontologies. Examples of automated reasoning engines include inference engines, theorem provers, and classifiers."
  },
  {
    "term": "knowledge-based system (KBS)",
    "definition": "A computer program that reasons and uses a knowledge base to solve complex problems. The term is broad and refers to many different kinds of systems. The one common theme that unites all knowledge based systems is an attempt to represent knowledge explicitly and a reasoning system that allows it to derive new knowledge. Thus, a knowledge-based system has two distinguishing features: a knowledge base and an inference engine."
  },
  {
    "term": "language model",
    "definition": "A probabilistic model that manipulates natural language."
  },
  {
    "term": "large language model (LLM)",
    "definition": "A language model with a large number of parameters (typically at least a billion) that are adjusted during training. Due to its size, it requires a lot of data and computing capability to train. Large language models are usually based on the transformer architecture.[224]"
  },
  {
    "term": "large-scale projects.[281]",
    "definition": "PyTorch A machine learning library based on the Torch library,[282][283][284] used for applications such as computer vision and natural language processing,[285] originally developed by Meta AI and now part of the Linux Foundation umbrella.[286][287][288][289] Q Q-learning A model-free reinforcement learning algorithm for learning the value of an action in a particular state."
  },
  {
    "term": "lazy learning",
    "definition": "In machine learning, lazy learning is a learning method in which generalization of the training data is, in theory, delayed until a query is made to the system, as opposed to in eager learning, where the system tries to generalize the training data before receiving queries."
  },
  {
    "term": "library (computing)",
    "definition": "A collection of non-volatile resources used by computer programs, often for software development. These may include configuration data, documentation, help data, message templates, pre-written code and subroutines, classes, values, or type specifications."
  },
  {
    "term": "linear search",
    "definition": "A method for finding an element within a list. It sequentially checks each element of the list until"
  },
  {
    "term": "linked list",
    "definition": "A linear collection of data elements, whose order is not given by their physical placement in memory. Instead, each element points to the next. It is a data structure consisting of a collection of nodes which together represent a sequence."
  },
  {
    "term": "linker",
    "definition": "or link editor, is a computer utility program that takes one or more object files generated by a compiler or an assembler and combines them into a single executable file, library file, or another 'object' file. A simpler version that writes its output directly to memory is called the loader, though loading is typically considered a separate process.[139]"
  },
  {
    "term": "Lisp (programming language) (LISP)",
    "definition": "A family of programming languages with a long history and a distinctive, fully"
  },
  {
    "term": "list",
    "definition": "An abstract data type that represents a countable number of ordered values, where the same value may occur more than once. An instance of a list is a computer representation of the mathematical concept of a finite sequence; the (potentially) infinite analog of a list is a stream.[140]: §3.5 Lists are a basic example of containers, as they contain other values. If the same value occurs multiple times, each occurrence is considered a distinct item."
  },
  {
    "term": "loader",
    "definition": "The part of an operating system that is responsible for loading programs and libraries. It is one of the essential stages in the process of starting a program, as it places programs into memory and prepares them for execution. Loading a program involves reading the contents of the executable file containing the program instructions into memory, and then carrying out other required preparatory tasks to prepare the executable for running. Once loading is complete, the operating system starts the program by passing control to the loaded program code."
  },
  {
    "term": "logic error",
    "definition": "In computer programming, a bug in a program that causes it to operate incorrectly, but not to terminate abnormally (or crash). A logic error produces unintended or undesired output or other behaviour, although it may not immediately be recognized as such."
  },
  {
    "term": "logic programming",
    "definition": "A type of programming paradigm which is largely based on formal logic. Any program written in a logic programming language is a set of sentences in logical form, expressing facts and rules about some problem domain. Major logic programming language families include Prolog, answer set programming (ASP), and Datalog. M"
  },
  {
    "term": "long short-term memory (LSTM)",
    "definition": "An artificial recurrent neural network architecture[226] used in the field of deep learning. Unlike standard feedforward neural networks, LSTM has feedback connections that make it a \"general purpose computer\" (that is, it can compute anything that a Turing machine can).[227] It can not only process single data points (such as images), but also entire sequences of data (such as speech or video)."
  },
  {
    "term": "lora",
    "definition": "LoRA stands for Low-Rank Adaptation. It is a method used to fine-tune large models by updating only a small, targeted part of the model. This makes it quicker and less resource- intensive to adapt the model to specific tasks or new datasets. M"
  },
  {
    "term": "machine learning (ML)",
    "definition": "The scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.[141][142]"
  },
  {
    "term": "machine listening",
    "definition": "A general field of study of algorithms and systems for audio understanding by"
  },
  {
    "term": "machine perception",
    "definition": "The capability of a computer system to interpret data in a manner that is similar to the way humans use their senses to relate to the world around them.[233][234][235]"
  },
  {
    "term": "machine vision (MV)",
    "definition": "The technology and methods used to provide imaging-based automatic inspection and analysis for such applications as automatic inspection, process control, and robot guidance, usually in industry. Machine vision refers to many technologies, software and hardware products, integrated systems, actions, methods and expertise. Machine vision as a systems engineering discipline can be considered distinct from computer vision, a form of computer science. It attempts to integrate existing technologies in new ways and apply them to solve real world problems. The term is the prevalent one for these functions in industrial automation environments but is also used for these functions in other environments such as security and vehicle guidance."
  },
  {
    "term": "Markov chain",
    "definition": "A stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.[228][229]"
  },
  {
    "term": "Markov decision process (MDP)",
    "definition": "A discrete time stochastic control process. It provides a mathematical framework for modeling decision making in situations where outcomes are partly random and partly under the control of a decision maker. MDPs are useful for studying optimization problems solved via dynamic programming and reinforcement learning."
  },
  {
    "term": "mathematical logic",
    "definition": "A subfield of mathematics exploring the applications of formal logic to mathematics. It bears close connections to metamathematics, the foundations of mathematics, and theoretical computer science.[143] The unifying themes in mathematical logic include the study of the expressive power of formal systems and the deductive power of formal proof systems."
  },
  {
    "term": "mathematical optimization",
    "definition": "In mathematics, computer science, and operations research, the selection of a best element (with regard to some criterion) from some set of available alternatives.[230]"
  },
  {
    "term": "matrix",
    "definition": "In mathematics, a matrix, (plural matrices), is a rectangular array[144] (see irregular matrix) of numbers, symbols, or expressions, arranged in rows and columns.[145][146]"
  },
  {
    "term": "mechanism design",
    "definition": "A field in economics and game theory that takes an engineering approach to designing economic mechanisms or incentives, toward desired objectives, in strategic settings, where players act rationally. Because it starts at the end of the game, then goes backwards, it is also called reverse game theory. It has broad applications, from economics and politics (markets, auctions, voting procedures) to networked-systems (internet interdomain routing, sponsored search auctions)."
  },
  {
    "term": "mechatronics",
    "definition": "A multidisciplinary branch of engineering that focuses on the engineering of both electrical and mechanical systems, and also includes a combination of robotics, electronics, computer, telecommunications, systems, control, and product engineering.[236][237]"
  },
  {
    "term": "memory",
    "definition": "Computer data storage, often called storage, is a technology consisting of computer components and recording media that are used to retain digital data. It is a core function and"
  },
  {
    "term": "merge sort",
    "definition": "An efficient, general-purpose, comparison-based sorting algorithm. Most implementations produce a stable sort, which means that the order of equal elements is the same in the input and output. Merge sort is a divide and conquer algorithm that was invented by John von Neumann in 1945.[147] A detailed description and analysis of bottom-up mergesort appeared in"
  },
  {
    "term": "metabolic network reconstruction and simulation",
    "definition": "Allows for an in-depth insight into the molecular mechanisms of a particular organism. In particular, these models correlate the genome with molecular physiology.[238]"
  },
  {
    "term": "metaheuristic",
    "definition": "In computer science and mathematical optimization, a metaheuristic is a higher-level procedure or heuristic designed to find, generate, or select a heuristic (partial search algorithm) that may provide a sufficiently good solution to an optimization problem, especially with incomplete or imperfect information or limited computation capacity.Metaheuristics sample a set of solutions which is too large to be completely sampled metal wires suffer"
  },
  {
    "term": "method",
    "definition": "In object-oriented programming (OOP), a procedure associated with a message and an object. An object consists of data and behavior. The data and behavior comprise an interface, which specifies how the object may be utilized by any of various consumers[149] of the object."
  },
  {
    "term": "methodology",
    "definition": "In software engineering, a software development process is the process of dividing software development work into distinct phases to improve design, product management, and project management. It is also known as a software development life cycle (SDLC). The methodology may include the pre-definition of specific deliverables and artifacts that are created and completed by a project team to develop or maintain an application.[150]"
  },
  {
    "term": "model checking",
    "definition": "In computer science, model checking or property checking is, for a given model of a system, exhaustively and automatically checking whether this model meets a given specification. Typically, one has hardware or software systems in mind, whereas the specification contains safety requirements such as the absence of deadlocks and similar critical states that can cause the system to crash. Model checking is a technique for automatically verifying correctness properties of finite-state systems."
  },
  {
    "term": "modem",
    "definition": "A hardware device that converts data into a format suitable for a transmission medium so that it can be transmitted from one computer to another (historically along telephone wires). A modem modulates one or more carrier wave signals to encode digital information for transmission and demodulates signals to decode the transmitted information. The goal is to produce a signal that can be transmitted easily and decoded reliably to reproduce the original digital data. Modems can be used with almost any means of transmitting analog signals from light-emitting diodes to radio. A common type of modem is one that turns the digital data of a computer into modulated electrical signal for transmission over telephone lines and demodulated by another modem at the receiver side to recover the digital data. N"
  },
  {
    "term": "modus ponens",
    "definition": "In propositional logic, modus ponens is a rule of inference.[241] It can be summarized as \"P implies Q and P is asserted to be true, therefore Q must be true.\""
  },
  {
    "term": "modus tollens",
    "definition": "In propositional logic, modus tollens is a valid argument form and a rule of inference. It is an application of the general truth that if a statement is true, then so is its contrapositive. The inference rule modus tollens asserts that the inference from P implies Q to the negation of Q implies the negation of P is valid."
  },
  {
    "term": "Monte Carlo tree search",
    "definition": "In computer science, Monte Carlo tree search (MCTS) is a heuristic search algorithm for some kinds of decision processes."
  },
  {
    "term": "multi-agent system (MAS)",
    "definition": "A computerized system composed of multiple interacting intelligent agents. Multi-agent systems can solve problems that are difficult or impossible for an individual agent or a monolithic system to solve. Intelligence may include methodic, functional, procedural approaches, algorithmic search or reinforcement learning."
  },
  {
    "term": "multi-swarm optimization",
    "definition": "A variant of particle swarm optimization (PSO) based on the use of multiple sub-swarms instead of one (standard) swarm. The general approach in multi-swarm optimization is that each sub-swarm focuses on a specific region while a specific diversification method decides where and when to launch the sub-swarms. The multi-swarm framework is especially fitted for the optimization on multi-modal problems, where multiple (local) optima exist."
  },
  {
    "term": "multilayer perceptron (MLP)",
    "definition": "In deep learning, a multilayer perceptron (MLP) is a name for a modern feedforward neural network consisting of fully connected neurons with nonlinear activation functions, organized in layers, notable for being able to distinguish data that is not linearly"
  },
  {
    "term": "mutation",
    "definition": "A genetic operator used to maintain genetic diversity from one generation of a population of genetic algorithm chromosomes to the next. It is analogous to biological mutation. Mutation alters one or more gene values in a chromosome from its initial state. In mutation, the solution may change entirely from the previous solution. Hence GA can come to a better solution by using mutation. Mutation occurs during evolution according to a user-definable mutation probability. This probability should be set low. If it is set too high, the search will turn into a primitive random search. Mycin An early backward chaining expert system that used artificial intelligence to identify bacteria causing severe infections, such as bacteremia and meningitis, and to recommend antibiotics, with the dosage adjusted for patient's body weight – the name derived from the antibiotics themselves, as many antibiotics have the suffix \"-mycin\". The MYCIN system was also used for the diagnosis of blood clotting diseases. N"
  },
  {
    "term": "naive Bayes classifier",
    "definition": "In machine learning, naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong (naive) independence assumptions between the features."
  },
  {
    "term": "naive semantics",
    "definition": "An approach used in computer science for representing basic knowledge about a specific domain, and has been used in applications such as the representation of the meaning of natural language sentences in artificial intelligence applications. In a general setting the term has been used to refer to the use of a limited store of generally understood knowledge about a specific domain in the world, and has been applied to fields such as"
  },
  {
    "term": "name binding",
    "definition": "In programming languages, name binding is the association of entities (data and/or code) with identifiers.[244] An identifier bound to an object is said to reference that object. Machine languages have no built-in notion of identifiers, but name-object bindings as a service and notation for the programmer is implemented by programming languages. Binding is intimately connected with scoping, as scope determines which names bind to which objects – at which locations in the program code (lexically) and in which one of the possible execution paths (temporally). Use of an identifier id in a context that establishes a binding for id is called a binding (or defining) occurrence. In all other occurrences (e.g., in expressions, assignments, and subprogram calls), an identifier stands for what it is bound to; such occurrences are called applied occurrences."
  },
  {
    "term": "named graph",
    "definition": "A key concept of Semantic Web architecture in which a set of Resource Description Framework statements (a graph) are identified using a URI,[245] allowing descriptions to be made of that set of statements such as context, provenance information or other such metadata. Named graphs are a simple extension of the RDF data model[246] through which graphs can be created but the model lacks an effective means of distinguishing between them once published on the Web at large."
  },
  {
    "term": "named-entity recognition (NER)",
    "definition": "A subtask of information extraction that seeks to locate and classify named entity mentions in unstructured text into pre-defined categories such as the person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc."
  },
  {
    "term": "natural language generation (NLG)",
    "definition": "A software process that transforms structured data into plain-English content. It can be used to produce long-form content for organizations to automate custom reports, as well as produce custom content for a web or mobile application. It can also be used to generate short blurbs of text in interactive conversations (a chatbot) which might even be read out loud by a text-to-speech system."
  },
  {
    "term": "natural language processing (NLP)",
    "definition": "A subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data. Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation."
  },
  {
    "term": "natural language programming",
    "definition": "An ontology-assisted way of programming in terms of natural-language sentences, e.g. English.[247]"
  },
  {
    "term": "network motif",
    "definition": "All networks, including biological networks, social networks, technological networks (e.g., computer networks and electrical circuits) and more, can be represented as graphs, which include a wide variety of subgraphs. One important local property of networks are so- called network motifs, which are defined as recurrent and statistically significant sub- graphs or patterns."
  },
  {
    "term": "neural machine translation (NMT)",
    "definition": "An approach to machine translation that uses a large artificial neural network to predict the likelihood of a sequence of words, typically modeling entire sentences in a single integrated model."
  },
  {
    "term": "neural network",
    "definition": "A neural network can refer to either a neural circuit of biological neurons (sometimes also called a biological neural network), or a network of artificial neurons or nodes in the case of an artificial neural network.[248] Artificial neural networks are used for solving artificial intelligence (AI) problems; they model connections of biological neurons as weights between nodes. A positive weight reflects an excitatory connection, while negative values mean inhibitory connections. All inputs are modified by a weight and summed. This activity is referred to as a linear combination. Finally, an activation function controls the amplitude of the output. For example, an acceptable range of output is usually between 0 and 1, or it could be −1 and 1."
  },
  {
    "term": "neural Turing machine (NTM)",
    "definition": "A recurrent neural network model. NTMs combine the fuzzy pattern matching capabilities of neural networks with the algorithmic power of programmable computers. An NTM has a neural network controller coupled to external memory resources, which it interacts with through attentional mechanisms. The memory interactions are differentiable end-to-end, making it possible to optimize them using gradient descent.[249] An NTM with a long short- term memory (LSTM) network controller can infer simple algorithms such as copying,"
  },
  {
    "term": "neuro-fuzzy",
    "definition": "Combinations of artificial neural networks and fuzzy logic."
  },
  {
    "term": "neurocybernetics",
    "definition": "A direct communication pathway between an enhanced or wired brain and an external device. BCI differs from neuromodulation in that it allows for bidirectional information flow. BCIs are often directed at researching, mapping, assisting, augmenting, or repairing"
  },
  {
    "term": "neuromorphic engineering",
    "definition": "A concept describing the use of very-large-scale integration (VLSI) systems containing electronic analog circuits to mimic neuro-biological architectures present in the nervous system.[252] In recent times, the term neuromorphic has been used to describe analog, digital, mixed-mode analog/digital VLSI, and software systems that implement models of neural systems (for perception, motor control, or multisensory integration). The implementation of neuromorphic computing on the hardware level can be realized by oxide-based memristors,[253] spintronic memories,[254] threshold switches, and"
  },
  {
    "term": "node",
    "definition": "Is a basic unit of a data structure, such as a linked list or tree data structure. Nodes contain data and also may link to other nodes. Links between nodes are often implemented by pointers."
  },
  {
    "term": "nondeterministic algorithm",
    "definition": "An algorithm that, even for the same input, can exhibit different behaviors on different runs, as opposed to a deterministic algorithm."
  },
  {
    "term": "nouvelle AI",
    "definition": "Nouvelle AI differs from classical AI by aiming to produce robots with intelligence levels similar to insects. Researchers believe that intelligence can emerge organically from simple behaviors as these intelligences interacted with the \"real world\", instead of using the constructed worlds which symbolic AIs typically needed to have programmed into"
  },
  {
    "term": "number theory",
    "definition": "A branch of pure mathematics devoted primarily to the study of the integers and integer-valued functions."
  },
  {
    "term": "numerical analysis",
    "definition": "The study of algorithms that use numerical approximation (as opposed to symbolic manipulations) for the problems of mathematical analysis (as distinguished from discrete mathematics)."
  },
  {
    "term": "numerical method",
    "definition": "In numerical analysis, a numerical method is a mathematical tool designed to solve numerical problems. The implementation of a numerical method with an appropriate convergence check in a programming language is called a numerical algorithm. O"
  },
  {
    "term": "object",
    "definition": "An object can be a variable, a data structure, a function, or a method, and as such, is a value in memory referenced by an identifier. In the class-based object-oriented programming paradigm, object refers to a particular instance of a class, where the object can be a combination of variables, functions, and data structures. In relational database management, an object can be a table or column, or an association between data and a database entity (such as relating a"
  },
  {
    "term": "object code",
    "definition": "The product of a compiler.[152] In a general sense object code is a sequence of statements or instructions in a computer language,[153] usually a machine code language (i.e., binary) or an intermediate language such as register transfer language (RTL). The term indicates that the code is the goal or result of the compiling process, with some early sources referring to source"
  },
  {
    "term": "object-oriented analysis and design (OOAD)",
    "definition": "A technical approach for analyzing and designing an application, system, or business by applying object-oriented programming, as well as using visual modeling throughout the software development process to guide stakeholder communication and product quality."
  },
  {
    "term": "object-oriented programming (OOP)",
    "definition": "A programming paradigm based on the concept of \"objects\", which can contain data, in the form of fields (often known as attributes or properties), and code, in the form of procedures (often known as methods). A feature of objects is an object's procedures that can access and often modify the data fields of the object with which they are associated (objects have a notion of \"this\" or \"self\"). In OOP, computer programs are designed by making them out of objects that interact with one another.[154][155] OOP languages are diverse, but the most popular ones are class-based, meaning that objects are instances of classes, which also determine their types."
  },
  {
    "term": "of variables are the branches.[217]",
    "definition": "K"
  },
  {
    "term": "offline learning",
    "definition": "A machine learning training approach in which a model is trained on a fixed dataset that is not updated during the learning process."
  },
  {
    "term": "online machine learning",
    "definition": "A method of machine learning in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once. Online learning is a common technique used in areas of machine learning where it is computationally infeasible to train over the entire dataset, requiring the need of out-of-core algorithms. It is also used in situations where it is necessary for the algorithm to dynamically adapt to new patterns in the data, or when the data itself is generated as a function of time."
  },
  {
    "term": "ontology learning",
    "definition": "The automatic or semi-automatic creation of ontologies, including extracting the corresponding domain's terms and the relationships between the concepts that these terms represent from a corpus of natural language text, and encoding them with an ontology language for easy retrieval. OpenAI The for-profit corporation OpenAI LP, whose parent organization is the non-profit organization OpenAI Inc[263] that conducts research in the field of artificial intelligence (AI) with the stated aim to promote and develop friendly AI in such a way as to benefit humanity as a whole. OpenCog A project that aims to build an open-source artificial intelligence framework. OpenCog Prime is an architecture for robot and virtual embodied cognition that defines a set of interacting components designed to give rise to human-equivalent artificial general intelligence (AGI) as an emergent phenomenon of the whole system.[264]"
  },
  {
    "term": "Open Mind Common Sense",
    "definition": "An artificial intelligence project based at the Massachusetts Institute of Technology (MIT) Media Lab whose goal is to build and utilize a large commonsense knowledge base from the contributions of many thousands of people across the Web."
  },
  {
    "term": "open-source software (OSS)",
    "definition": "A type of computer software in which source code is released under a license in which the copyright holder grants users the rights to study, change, and distribute the software to anyone and for any purpose.[156] Open-source software may be developed in a collaborative public manner. Open-source software is a prominent example of open collaboration.[157]"
  },
  {
    "term": "operating system (OS)",
    "definition": "System software that manages computer hardware, software resources, and provides common services for computer programs."
  },
  {
    "term": "optical fiber",
    "definition": "A flexible, transparent fiber made by drawing glass (silica) or plastic to a diameter slightly thicker than that of a human hair.[158] Optical fibers are used most often as a means to transmit light between the two ends of the fiber and find wide usage in fiber-optic communications, where they permit transmission over longer distances and at higher bandwidths (data rates) than electrical cables. Fibers are used instead of metal wires because signals travel along them with less loss; in addition, fibers are immune to electromagnetic interference, a problem from which"
  },
  {
    "term": "overfitting",
    "definition": "\"The production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit to additional data or predict future observations reliably\".[267] In other words, an overfitted model memorizes training data details but cannot generalize to new data. Conversely, an underfitted model is too simple to capture the complexity of the training data. P"
  },
  {
    "term": "pair programming",
    "definition": "An agile software development technique in which two programmers work together at one workstation. One, the driver, writes code while the other, the observer or navigator,[160] reviews each line of code as it is typed in. The two programmers switch roles frequently."
  },
  {
    "term": "parallel computing",
    "definition": "A type of computation in which many calculations or the execution of processes are carried out simultaneously.[161] Large problems can often be divided into smaller ones, which can then be solved at the same time. There are several different forms of parallel computing: bit-level, instruction-level, data, and task parallelism."
  },
  {
    "term": "parameter",
    "definition": "In computer programming, a special kind of variable, used in a subroutine to refer to one of the pieces of data provided as input to the subroutine.[b] These pieces of data are the values[162][163][164] of the arguments (often called actual arguments or actual parameters) with which the subroutine is going to be called/invoked. An ordered list of parameters is usually included in the definition of a subroutine, so that, each time the subroutine is called, its arguments for that call are evaluated, and the resulting values can be assigned to the corresponding parameters."
  },
  {
    "term": "partial order reduction",
    "definition": "A technique for reducing the size of the state-space to be searched by a model checking or automated planning and scheduling algorithm. It exploits the commutativity of concurrently executed transitions, which result in the same state when executed in different orders."
  },
  {
    "term": "partially observable Markov decision process (POMDP)",
    "definition": "A generalization of a Markov decision process (MDP). A POMDP models an agent decision process in which it is assumed that the system dynamics are determined by an MDP, but the agent cannot directly observe the underlying state. Instead, it must maintain a probability distribution over the set of possible states, based on a set of observations and observation probabilities, and the underlying MDP."
  },
  {
    "term": "particle swarm optimization (PSO)",
    "definition": "A computational method that optimizes a problem by iteratively trying to improve a candidate solution with regard to a given measure of quality. It solves a problem by having a population of candidate solutions, here dubbed particles, and moving these particles around in the search-space according to simple mathematical formulae over the particle's position and velocity. Each particle's movement is influenced by its local best known position, but is also guided toward the best known positions in the search-space, which are updated as better positions are found by other particles. This is expected to move the swarm toward the best solutions."
  },
  {
    "term": "pathfinding",
    "definition": "The plotting, by a computer application, of the shortest route between two points. It is a more practical variant on solving mazes. This field of research is based heavily on Dijkstra's algorithm for finding a shortest path on a weighted graph."
  },
  {
    "term": "pattern recognition",
    "definition": "Concerned with the automatic discovery of regularities in data through the use of computer algorithms and with the use of these regularities to take actions such as"
  },
  {
    "term": "perceptron",
    "definition": "An algorithm for supervised learning of binary classifiers."
  },
  {
    "term": "peripheral",
    "definition": "Any auxiliary or ancillary device connected to or integrated within a computer system and used to send information to or retrieve information from the computer. An input device sends data or instructions to the computer; an output device provides output from the computer to the user; and an input/output device performs both functions picture of a problem.\"\""
  },
  {
    "term": "pointer",
    "definition": "Is an object in many programming languages that stores a memory address. This can be that of another value located in computer memory, or in some cases, that of memory-mapped computer hardware. A pointer references a location in memory, and obtaining the value stored at that location is known as dereferencing the pointer. As an analogy, a page number in a book's index could be considered a pointer to the corresponding page; dereferencing such a pointer would be done by flipping to the page with the given page number and reading the text found on that page. The actual format and content of a pointer variable is dependent on the underlying computer architecture."
  },
  {
    "term": "postcondition",
    "definition": "In computer programming, a condition or predicate that must always be true just after the execution of some section of code or after an operation in a formal specification. Postconditions are sometimes tested using assertions within the code itself. Often, postconditions are simply included in the documentation of the affected section of code."
  },
  {
    "term": "precondition",
    "definition": "In computer programming, a condition or predicate that must always be true just prior to the execution of some section of code or before an operation in a formal specification. If a precondition is violated, the effect of the section of code becomes undefined and thus may or may not carry out its intended work. Security problems can arise due to incorrect preconditions."
  },
  {
    "term": "predicate logic",
    "definition": "A collection of formal systems used in mathematics, philosophy, linguistics, and computer science. First-order logic uses quantified variables over non-logical objects and allows the use of sentences that contain variables, so that rather than propositions such as Socrates is a man one can have expressions in the form \"there exists x such that x is Socrates and x is a man\" and there exists is a quantifier while x is a variable.[182] This distinguishes it from propositional logic, which does not use quantifiers or relations;[269] in this sense, propositional logic is the foundation of first-order logic."
  },
  {
    "term": "predictive analytics",
    "definition": "A variety of statistical techniques from data mining, predictive modelling, and machine learning, that analyze current and historical facts to make predictions about future or"
  },
  {
    "term": "primary storage",
    "definition": "(Also known as main memory, internal memory or prime memory), often referred to simply as memory, is the only one directly accessible to the CPU. The CPU continuously reads instructions stored there and executes them as required. Any data actively operated on is also stored there in uniform manner."
  },
  {
    "term": "principal component analysis (PCA)",
    "definition": "A statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables (entities each of which takes on various numerical values) into a set of values of linearly uncorrelated variables called principal components. This transformation is defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component, in turn, has the highest variance possible under the constraint that it is orthogonal to the preceding components. The resulting vectors (each being a linear combination of the variables and containing n observations) are an uncorrelated orthogonal basis set. PCA is sensitive to the relative scaling of the original variables."
  },
  {
    "term": "principle of rationality",
    "definition": "A principle coined by Karl R. Popper in his Harvard Lecture of 1963, and published in his book Myth of Framework.[272] It is related to what he called the 'logic of the situation' in an Economica article of 1944/1945, published later in his book The Poverty of Historicism.[273] According to Popper's rationality principle, agents act in the most adequate way according to the objective situation. It is an idealized conception of human behavior which he used to drive his model of situational logic."
  },
  {
    "term": "priority queue",
    "definition": "An abstract data type which is like a regular queue or stack data structure, but where additionally each element has a \"priority\" associated with it. In a priority queue, an element with high priority is served before an element with low priority. In some implementations, if two elements have the same priority, they are served according to the order in which they were enqueued, while in other implementations, ordering of elements with the same priority is undefined."
  },
  {
    "term": "probabilistic programming (PP)",
    "definition": "A programming paradigm in which probabilistic models are specified and inference for these models is performed automatically.[274] It represents an attempt to unify probabilistic modeling and traditional general-purpose programming in order to make the former easier and more widely applicable.[275][276] It can be used to create systems that help make decisions in the face of uncertainty. Programming languages used for probabilistic programming are referred to as \"Probabilistic programming languages\" (PPLs)."
  },
  {
    "term": "procedure",
    "definition": "In computer programming, a subroutine is a sequence of program instructions that performs a specific task, packaged as a unit. This unit can then be used in programs wherever that particular task should be performed. Subroutines may be defined within programs, or separately in libraries that can be used by many programs. In different programming languages, a subroutine may be called a routine, subprogram, function, method, or procedure. Technically, these terms all have different definitions. The generic, umbrella term callable unit is sometimes"
  },
  {
    "term": "production system",
    "definition": "A computer program typically used to provide some form of AI, which consists primarily of a set of rules about behavior, but also includes the mechanism necessary to follow those rules as the system responds to states of the world."
  },
  {
    "term": "program lifecycle phase",
    "definition": "Program lifecycle phases are the stages a computer program undergoes, from initial creation to deployment and execution. The phases are edit time, compile time, link time, distribution time, installation time, load time, and run time."
  },
  {
    "term": "programming language",
    "definition": "A formal language, which comprises a set of instructions that produce various kinds of output. Programming languages are used in computer programming to implement algorithms."
  },
  {
    "term": "programming language implementation",
    "definition": "Is a system for executing computer programs. There are two general approaches to programming language implementation: interpretation and compilation.[166]"
  },
  {
    "term": "programming language theory",
    "definition": "(PLT) is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and of their individual features. It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, linguistics and even cognitive science. It has become a well-recognized branch of computer science, and an active research area, with results published in numerous journals dedicated to PLT, as well as in general computer science and engineering publications. Prolog Is a logic programming language associated with artificial intelligence and computational linguistics.[167][168][169] Prolog has its roots in first-order logic, a formal logic, and unlike many other programming languages, Prolog is intended primarily as a declarative programming language: the program logic is expressed in terms of relations, represented as facts and rules. A computation is initiated by running a query over these relations.[170] Python Is an interpreted, high-level and general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale"
  },
  {
    "term": "propositional calculus",
    "definition": "A branch of logic which deals with propositions (which can be true or false) and argument flow. Compound propositions are formed by connecting propositions by logical connectives. The propositions without logical connectives are called atomic propositions. Unlike first-order logic, propositional logic does not deal with non-logical objects, predicates about them, or quantifiers. However, all the machinery of propositional logic is included in first-order logic and higher-order logics. In this sense, propositional logic is the foundation of first-order logic and higher-order logic."
  },
  {
    "term": "proximal policy optimization (PPO)",
    "definition": "A reinforcement learning algorithm for training an intelligent agent's decision function to accomplish difficult tasks. Python An interpreted, high-level, general-purpose programming language created by Guido van Rossum and first released in 1991. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and"
  },
  {
    "term": "push, which adds an element to the collection, and",
    "definition": "pop, which removes the most recently added element that was not yet removed. The order in which elements come off a stack gives rise to its alternative name, LIFO (last in, first out). Additionally, a peek operation may give access to the top without modifying the stack.[217] The name \"stack\" for this type of structure comes from the analogy to a set of physical items stacked on top of each other. This structure makes it easy to take an item off the top of the stack, while getting to an item deeper in the stack may require taking off multiple other"
  },
  {
    "term": "qualification problem",
    "definition": "In philosophy and artificial intelligence (especially knowledge-based systems), the qualification problem is concerned with the impossibility of listing all of the preconditions required for a real-world action to have its intended effect.[290][291] It might be posed as how to deal with the things that prevent me from achieving my intended result. It is strongly connected to, and opposite the ramification side of, the frame problem.[290]"
  },
  {
    "term": "quantifier",
    "definition": "In logic, quantification specifies the quantity of specimens in the domain of discourse that satisfy an open formula. The two most common quantifiers mean \"for all\" and \"there exists\". For example, in arithmetic, quantifiers allow one to say that the natural numbers go on forever, by writing that for all n (where n is a natural number), there is another number (say, the successor of n) which is one bigger than n."
  },
  {
    "term": "quantum computing",
    "definition": "The use of quantum-mechanical phenomena such as superposition and entanglement to perform computation. A quantum computer is used to perform such computation, which can be"
  },
  {
    "term": "query language",
    "definition": "Query languages or data query languages (DQLs) are computer languages used to make queries in databases and information systems. Broadly, query languages can be classified according to whether they are database query languages or information retrieval query languages. The difference is that a database query language attempts to give factual answers to factual questions, while an information retrieval query language attempts to find documents containing information that is relevant to an area of inquiry. R"
  },
  {
    "term": "queue",
    "definition": "A collection in which the entities in the collection are kept in order and the principal (or only) operations on the collection are the addition of entities to the rear terminal position, known as enqueue, and removal of entities from the front terminal position, known as dequeue."
  },
  {
    "term": "quicksort",
    "definition": "An efficient sorting algorithm which serves as a systematic method for placing the elements of a random access file or an array in order. R"
  },
  {
    "term": "R programming language",
    "definition": "R is a programming language and free software environment for statistical computing and graphics supported by the R Foundation for Statistical Computing.[173] The R language is widely used among statisticians and data miners for developing statistical software [174] and data"
  },
  {
    "term": "radial basis function network",
    "definition": "In the field of mathematical modeling, a radial basis function network is an artificial neural network that uses radial basis functions as activation functions. The output of the network is a linear combination of radial basis functions of the inputs and neuron parameters. Radial basis function networks have many uses, including function approximation, time series prediction, classification, and system control. They were first formulated in a 1988 paper by Broomhead and Lowe, both researchers at the Royal Signals and Radar Establishment.[296][297][298]"
  },
  {
    "term": "radix",
    "definition": "In digital numeral systems, the number of unique digits, including the digit zero, used to represent numbers in a positional numeral system. For example, in the decimal/denary system (the most common system in use today) the radix (base number) is ten, because it uses the ten digits from 0 through 9, and all other numbers are uniquely specified by positional combinations of these ten base digits; in the binary system that is the standard in computing, the radix is two, because it uses only two digits, 0 and 1, to uniquely specify each number."
  },
  {
    "term": "random forest",
    "definition": "An ensemble learning method for classification, regression, and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.[299][300] Random decision forests correct for decision trees' habit of overfitting to"
  },
  {
    "term": "reasoning system",
    "definition": "In information technology a reasoning system is a software system that generates conclusions from available knowledge using logical techniques such as deduction and induction. Reasoning systems play an important role in the implementation of artificial intelligence and knowledge-based systems."
  },
  {
    "term": "record",
    "definition": "A record (also called a structure, struct, or compound data) is a basic data structure. Records in a database or spreadsheet are usually called \"rows\".[176][177][178][179]"
  },
  {
    "term": "recurrent neural network (RNN)",
    "definition": "A class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Unlike feedforward neural networks, RNNs can use their internal state (memory) to process sequences of inputs. This makes them applicable to tasks such as unsegmented, connected handwriting recognition [302] or speech recognition.[303][304]"
  },
  {
    "term": "recursion",
    "definition": "Occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references can occur."
  },
  {
    "term": "reference",
    "definition": "Is a value that enables a program to indirectly access a particular datum, such as a variable's value or a record, in the computer's memory or in some other storage device. The reference is said to refer to the datum, and accessing the datum is called dereferencing the reference."
  },
  {
    "term": "reference counting",
    "definition": "A programming technique of storing the number of references, pointers, or handles to a resource, such as an object, a block of memory, disk space, and others. In garbage collection algorithms, reference counts may be used to deallocate objects which are no longer needed."
  },
  {
    "term": "regression analysis",
    "definition": "A set of statistical processes for estimating the relationships between a dependent variable (often called the outcome or response variable, or label in machine learning) and one or more error-free independent variables (often called regressors, predictors, covariates, explanatory variables, or features). The most common form of regression analysis is linear regression, in which one finds the line (or a more complex linear combination) that most closely fits the data according to a specific mathematical criterion."
  },
  {
    "term": "regression testing",
    "definition": "(rarely non-regression testing[180]) is re-running functional and non-functional tests to ensure that previously developed and tested software still performs after a change.[181] If not, that would be called a regression. Changes that may require regression testing include bug fixes, software enhancements, configuration changes, and even substitution of electronic components.[182] As regression test suites tend to grow with each found defect, test automation is frequently involved. Sometimes a change impact analysis is performed to determine an appropriate subset of tests (non-regression analysis[183])."
  },
  {
    "term": "regularization",
    "definition": "A set of techniques such as dropout, early stopping, and L1 and L2 regularization to reduce overfitting and underfitting when training a learning algorithm."
  },
  {
    "term": "reinforcement learning (RL)",
    "definition": "An area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised and unsupervised learning. It differs from supervised learning in that labelled input/output pairs need not be presented, and sub-optimal actions need not be explicitly corrected. Instead the focus is finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).[305]"
  },
  {
    "term": "reinforcement learning from human feedback (RLHF)",
    "definition": "A technique that involve training a \"reward model\" to predict how humans rate the quality of generated content, and then training a generative AI model to satisfy this reward model via reinforcement learning. It can be used for example to make the generative AI model"
  },
  {
    "term": "relational database",
    "definition": "Is a digital database based on the relational model of data, as proposed by E. F. Codd in 1970.[184] A software system used to maintain relational databases is a relational database management system (RDBMS). Many relational database systems have an option of using the SQL (Structured Query Language) for querying and maintaining the database.[185]"
  },
  {
    "term": "reliability engineering",
    "definition": "A sub-discipline of systems engineering that emphasizes dependability in the lifecycle management of a product. Reliability describes the ability of a system or component to function under stated conditions for a specified period of time.[186] Reliability is closely related to availability, which is typically described as the ability of a component or system to function at a specified moment or interval of time."
  },
  {
    "term": "representation learning",
    "definition": "See feature learning."
  },
  {
    "term": "requirements analysis",
    "definition": "In systems engineering and software engineering, requirements analysis focuses on the tasks that determine the needs or conditions to meet the new or altered product or project, taking account of the possibly conflicting requirements of the various stakeholders, analyzing, documenting, validating and managing software or system requirements.[187]"
  },
  {
    "term": "reservoir computing",
    "definition": "A framework for computation that may be viewed as an extension of neural networks.[307] Typically an input signal is fed into a fixed (random) dynamical system called a reservoir and the dynamics of the reservoir map the input to a higher dimension. Then a simple readout mechanism is trained to read the state of the reservoir and map it to the desired output. The main benefit is that training is performed only at the readout stage and the reservoir is fixed. Liquid-state machines[308] and echo state networks[309] are two major"
  },
  {
    "term": "Resource Description Framework (RDF)",
    "definition": "A family of World Wide Web Consortium (W3C) specifications[311] originally designed as a metadata data model. It has come to be used as a general method for conceptual description or modeling of information that is implemented in web resources, using a variety of syntax notations and data serialization formats. It is also used in knowledge management applications."
  },
  {
    "term": "restricted Boltzmann machine (RBM)",
    "definition": "A generative stochastic artificial neural network that can learn a probability distribution over its set of inputs."
  },
  {
    "term": "Rete algorithm",
    "definition": "A pattern matching algorithm for implementing rule-based systems. The algorithm was developed to efficiently apply many rules or patterns to many objects, or facts, in a knowledge base. It is used to determine which of the system's rules should fire based on its data store, its facts."
  },
  {
    "term": "Retrieval augmented generation (RAG)",
    "definition": "A technique that enables large language models (LLMs) to retrieve and incorporate new information."
  },
  {
    "term": "robotics",
    "definition": "An interdisciplinary branch of engineering and science that includes mechanical engineering, electronic engineering, information engineering, computer science, and others. Robotics involves design, construction, operation, and use of robots, as well as computer systems for their perception, control, sensory feedback, and information processing. The goal of robotics is to design intelligent machines that can help and assist humans in their day-to-day lives and keep everyone safe."
  },
  {
    "term": "round-off error",
    "definition": "The difference between the result produced by a given algorithm using exact arithmetic and the result produced by the same algorithm using finite-precision, rounded arithmetic.[189] Rounding errors are due to inexactness in the representation of real numbers and the arithmetic operations done with them. This is a form of quantization error.[190] When using approximation equations or algorithms, especially when using finitely many digits to represent real numbers (which in theory have infinitely many digits), one of the goals of numerical analysis is to estimate computation errors.[191] Computation errors, also called numerical errors, include both"
  },
  {
    "term": "router",
    "definition": "A networking device that forwards data packets between computer networks. Routers perform the traffic directing functions on the Internet. Data sent through the internet, such as a web page or email, is in the form of data packets. A packet is typically forwarded from one router to another router through the networks that constitute an internetwork (e.g. the Internet) until it"
  },
  {
    "term": "routing table",
    "definition": "In computer networking a routing table, or routing information base (RIB), is a data table stored in a router or a network host that lists the routes to particular network destinations, and in some cases, metrics (distances) associated with those routes. The routing table contains information about the topology of the network immediately around it."
  },
  {
    "term": "rule-based system",
    "definition": "In computer science, a rule-based system is used to store and manipulate knowledge to interpret information in a useful way. It is often used in artificial intelligence applications and research. Normally, the term rule-based system is applied to systems involving human-crafted or curated rule sets. Rule-based systems constructed using automatic rule inference, such as rule-based machine learning, are normally excluded from this system type. S"
  },
  {
    "term": "run time",
    "definition": "Runtime, run time, or execution time is the final phase of a computer program's life cycle, in which the code is being executed on the computer's central processing unit (CPU) as machine code. In other words, \"runtime\" is the running phase of a program."
  },
  {
    "term": "run time error",
    "definition": "A runtime error is detected after or during the execution (running state) of a program, whereas a compile-time error is detected by the compiler before the program is ever executed. Type checking, register allocation, code generation, and code optimization are typically done at compile time, but may be done at runtime depending on the particular language and compiler. Many other runtime errors exist and are handled differently by different programming languages, such as division by zero errors, domain errors, array subscript out of bounds errors, arithmetic underflow errors, several types of underflow and overflow errors, and many other runtime errors generally considered as software bugs which may or may not be caught and handled by any particular computer language. S"
  },
  {
    "term": "satisfiability",
    "definition": "In mathematical logic, satisfiability and validity are elementary concepts of semantics. A formula is satisfiable if it is possible to find an interpretation (model) that makes the formula true.[312] A formula is valid if all interpretations make the formula true. The opposites of these concepts are unsatisfiability and invalidity, that is, a formula is unsatisfiable if none of the interpretations make the formula true, and invalid if some such interpretation makes the formula false. These four concepts are related to each other in a manner exactly analogous to Aristotle's square of opposition."
  },
  {
    "term": "score networks, and stochastic differential equations.[156]",
    "definition": "Dijkstra's algorithm An algorithm for finding the shortest paths between nodes in a weighted graph, which may represent, for example, road networks."
  },
  {
    "term": "search algorithm",
    "definition": "Any algorithm which solves the search problem, namely, to retrieve information stored within some data structure, or calculated in the search space of a problem domain, either with discrete or continuous values."
  },
  {
    "term": "secondary storage",
    "definition": "Also known as external memory or auxiliary storage, differs from primary storage in that it is not directly accessible by the CPU. The computer usually uses its input/output channels to access secondary storage and transfer the desired data to primary storage. Secondary storage is non- volatile (retaining data when power is shut off). Modern computer systems typically have two orders of magnitude more secondary storage than primary storage because secondary storage is less expensive."
  },
  {
    "term": "selection",
    "definition": "The stage of a genetic algorithm in which individual genomes are chosen from a population for later breeding (using the crossover operator)."
  },
  {
    "term": "selection sort",
    "definition": "Is an in-place comparison sorting algorithm. It has an O(n2) time complexity, which makes it inefficient on large lists, and generally performs worse than the similar insertion sort. Selection sort is noted for its simplicity and has performance advantages over more complicated algorithms in certain situations, particularly where auxiliary memory is limited."
  },
  {
    "term": "Selective Linear Definite clause resolution",
    "definition": "The basic inference rule used in logic programming. It is a refinement of resolution, which is both sound and refutation complete for Horn clauses."
  },
  {
    "term": "self-management",
    "definition": "The process by which computer systems manage their own operation without human intervention."
  },
  {
    "term": "semantic network",
    "definition": "A knowledge base that represents semantic relations between concepts in a network. This is often used as a form of knowledge representation. It is a directed or undirected graph consisting of vertices, which represent concepts, and edges, which represent semantic relations between concepts,[313] mapping or connecting semantic fields."
  },
  {
    "term": "semantic query",
    "definition": "Allows for queries and analytics of associative and contextual nature. Semantic queries enable the retrieval of both explicitly and implicitly derived information based on syntactic, semantic and structural information contained in data. They are designed to deliver precise results (possibly the distinctive selection of one single piece of information) or to answer more fuzzy and wide-open questions through pattern matching and digital reasoning."
  },
  {
    "term": "semantic reasoner",
    "definition": "A piece of software able to infer logical consequences from a set of asserted facts or axioms. The notion of a semantic reasoner generalizes that of an inference engine, by providing a richer set of mechanisms to work with. The inference rules are commonly specified by means of an ontology language, and often a description logic language. Many reasoners use first-order predicate logic to perform reasoning; inference commonly proceeds by forward chaining and backward chaining."
  },
  {
    "term": "semantics",
    "definition": "In programming language theory, semantics is the field concerned with the rigorous mathematical study of the meaning of programming languages. It does so by evaluating the meaning of syntactically valid strings defined by a specific programming language, showing the computation involved. In such a case that the evaluation would be of syntactically invalid strings, the result would be non-computation. Semantics describes the processes a computer follows when executing a program in that specific language. This can be shown by describing the relationship between the input and output of a program, or an explanation of how the program will be executed on a certain platform, hence creating a model of computation."
  },
  {
    "term": "semi-supervised learning",
    "definition": "A machine learning training paradigm characterized by using a combination of a small amount of human-labeled data (used exclusively in supervised learning), followed by a large amount of unlabeled data (used exclusively in unsupervised learning)."
  },
  {
    "term": "sensor fusion",
    "definition": "The combining of sensory data or data derived from disparate sources such that the resulting information has less uncertainty than would be possible when these sources were used individually."
  },
  {
    "term": "separation logic",
    "definition": "An extension of Hoare logic, a way of reasoning about programs. The assertion language of separation logic is a special case of the logic of bunched implications (BI).[314]"
  },
  {
    "term": "sequence",
    "definition": "In mathematics, a sequence is an enumerated collection of objects in which repetitions are allowed and order does matter. Like a set, it contains members (also called elements, or terms). The number of elements (possibly infinite) is called the length of the sequence. Unlike a set, the same elements can appear multiple times at different positions in a sequence, and order does matter. Formally, a sequence can be defined as a function whose domain is either the set of the natural numbers (for infinite sequences) or the set of the first n natural numbers (for a sequence of finite length n). The position of an element in a sequence is its rank or index; it is the natural number for which the element is the image. The first element has index 0 or 1, depending on the context or a specific convention. When a symbol is used to denote a sequence, the nth element of the sequence is denoted by this symbol with n as subscript; for example, the nth element of the Fibonacci sequence F is generally denoted F . For example, (M, A, R, Y) is a sequence of letters with the letter 'M' first and 'Y' last. This sequence differs from (A, R, M, Y). Also, the sequence (1, 1, 2, 3, 5, 8), which contains the number 1 at two different positions, is a valid sequence. Sequences can be finite, as in these examples, or infinite, such as the sequence of all even positive integers (2, 4, 6, ...). In computing and computer science, finite sequences are sometimes called strings, words or lists, the different names commonly corresponding to different ways to represent them in computer memory; infinite sequences are called streams. The empty sequence ( ) is included in most notions of sequence, but may be excluded depending on the context."
  },
  {
    "term": "serializability",
    "definition": "In concurrency control of databases,[194][195] transaction processing (transaction management), and various transactional applications (e.g., transactional memory [196] and software transactional memory), both centralized and distributed, a transaction schedule is serializable if its outcome (e.g., the resulting database state) is equal to the outcome of its transactions executed serially, i.e. without overlapping in time. Transactions are normally executed concurrently (they overlap), since this is the most efficient way. Serializability is the major correctness criterion for concurrent transactions' executions. It is considered the highest level of isolation between transactions, and plays an essential role in concurrency control. As such it is supported in all general purpose database systems. Strong strict two-phase locking (SS2PL) is a popular serializability mechanism utilized in most of the database systems (in various variants) since their early days in the 1970s."
  },
  {
    "term": "serialization",
    "definition": "Is the process of translating data structures or object state into a format that can be stored (for example, in a file or memory buffer) or transmitted (for example, across a network connection link) and reconstructed later (possibly in a different computer environment).[197] When the resulting series of bits is reread according to the serialization format, it can be used to create a semantically identical clone of the original object. For many complex objects, such as those that make extensive use of references, this process is not straightforward. Serialization of object- oriented objects does not include any of their associated methods with which they were previously linked. This process of serializing an object is also called marshalling an object in some situations.[198][199] The opposite operation, extracting a data structure from a series of bytes, is deserialization, (also called unserialization or unmarshalling)."
  },
  {
    "term": "server",
    "definition": "A computer that provides information to other computers called \"clients\" on a computer network.[200] This architecture is called the client–server model."
  },
  {
    "term": "service level agreement",
    "definition": "(SLA), is a commitment between a service provider and a client. Particular aspects of the service – quality, availability, responsibilities – are agreed between the service provider and the service user.[201] The most common component of an SLA is that the services should be provided to the customer as agreed upon in the contract. As an example, Internet service providers and telcos will commonly include service level agreements within the terms of their contracts with customers to define the level(s) of service being sold in plain language terms. In this case the SLA will typically have a technical definition in mean time between failures (MTBF), mean time to repair or mean time to recovery (MTTR); identifying which party is responsible for reporting faults or paying fees; responsibility for various data rates; throughput; jitter; or similar measurable details."
  },
  {
    "term": "set",
    "definition": "Is an abstract data type that can store unique values, without any particular order. It is a computer implementation of the mathematical concept of a finite set. Unlike most other collection types, rather than retrieving a specific element from a set, one typically tests a value for membership in a set."
  },
  {
    "term": "similarity learning",
    "definition": "An area of supervised learning closely related to classification and regression, but the goal is to learn from a similarity function that measures how similar or related two objects are. It has applications in ranking, in recommendation systems, visual identity tracking, face verification, and speaker verification."
  },
  {
    "term": "simulated annealing (SA)",
    "definition": "A probabilistic technique for approximating the global optimum of a given function. Specifically, it is a metaheuristic to approximate global optimization in a large search space for an optimization problem."
  },
  {
    "term": "singleton",
    "definition": "Pertains to an element that appears exactly once. In object-oriented programming, a singleton class has exactly one instance. In mathematics, a singleton is a set having exactly one element. In linguistics, a hapax legomenon is a term that appears exactly once in some corpus. In programming, a singleton variable, occurring only once, might be a dummy argument or a mistake that can be detected by a linter. Contrast unique."
  },
  {
    "term": "situated approach",
    "definition": "In artificial intelligence research, the situated approach builds agents that are designed to behave effectively successfully in their environment. This requires designing AI \"from the bottom-up\" by focussing on the basic perceptual and motor skills required to survive. The situated approach gives a much lower priority to abstract reasoning or problem-solving skills."
  },
  {
    "term": "situation calculus",
    "definition": "A logic formalism designed for representing and reasoning about dynamical domains."
  },
  {
    "term": "software",
    "definition": "Computer software, or simply software, is a collection of data or computer instructions that tell the computer how to work. This is in contrast to physical hardware, from which the system is built and actually performs the work. In computer science and software engineering, computer software is all information processed by computer systems, programs and data. Computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. Computer hardware and software require each other and neither can be realistically used on its own."
  },
  {
    "term": "software agent",
    "definition": "Is a computer program that acts for a user or other program in a relationship of agency, which derives from the Latin agere (to do): an agreement to act on one's behalf. Such \"action on behalf of\" implies the authority to decide which, if any, action is appropriate.[202][203] Agents are colloquially known as bots, from robot. They may be embodied, as when execution is paired with a robot body, or as software such as a chatbot executing on a phone (e.g. Siri) or other computing device. Software agents may be autonomous or work together with other agents or people. Software agents interacting with people (e.g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo)."
  },
  {
    "term": "software construction",
    "definition": "Is a software engineering discipline. It is the detailed creation of working meaningful software through a combination of coding, verification, unit testing, integration testing, and debugging. It is linked to all the other software engineering disciplines, most strongly to software design and"
  },
  {
    "term": "software deployment",
    "definition": "Is all of the activities that make a software system available for use.[205]"
  },
  {
    "term": "software design",
    "definition": "Is the process by which an agent creates a specification of a software artifact, intended to accomplish goals, using a set of primitive components and subject to constraints.[206] Software design may refer to either \"all the activity involved in conceptualizing, framing, implementing, commissioning, and ultimately modifying complex systems\" or \"the activity following requirements specification and before programming, as ... [in] a stylized software engineering"
  },
  {
    "term": "software development",
    "definition": "Is the process of conceiving, specifying, designing, programming, documenting, testing, and bug fixing involved in creating and maintaining applications, frameworks, or other software components. Software development is a process of writing and maintaining the source code, but in a broader sense, it includes all that is involved between the conception of the desired software through to the final manifestation of the software, sometimes in a planned and structured process.[208] Therefore, software development may include research, new development, prototyping, modification, reuse, re-engineering, maintenance, or any other"
  },
  {
    "term": "software development process",
    "definition": "In software engineering, a software development process is the process of dividing software development work into distinct phases to improve design, product management, and project management. It is also known as a software development life cycle (SDLC). The methodology may include the pre-definition of specific deliverables and artifacts that are created and completed by a project team to develop or maintain an application.[150] Most modern development processes can be vaguely described as agile. Other methodologies include waterfall, prototyping, iterative and incremental development, spiral development, rapid application development, and extreme programming."
  },
  {
    "term": "software engineering",
    "definition": "Is the systematic application of engineering approaches to the development of software.[210][211][212] Software engineering is a computing discipline.[213]"
  },
  {
    "term": "software maintenance",
    "definition": "In software engineering is the modification of a software product after delivery to correct faults,"
  },
  {
    "term": "software prototyping",
    "definition": "Is the activity of creating prototypes of software applications, i.e., incomplete versions of the software program being developed. It is an activity that can occur in software development and is comparable to prototyping as known from other fields, such as mechanical engineering or manufacturing. A prototype typically simulates only a few aspects of, and may be completely different from, the final product."
  },
  {
    "term": "software requirements specification",
    "definition": "(SRS), is a description of a software system to be developed. The software requirements specification lays out functional and non-functional requirements, and it may include a set of use cases that describe user interactions that the software must provide to the user for perfect interaction."
  },
  {
    "term": "software testing",
    "definition": "Is an investigation conducted to provide stakeholders with information about the quality of the software product or service under test.[215] Software testing can also provide an objective, independent view of the software to allow the business to appreciate and understand the risks of software implementation. Test techniques include the process of executing a program or application with the intent of finding software bugs (errors or other defects), and verifying that the software product is fit for use."
  },
  {
    "term": "sorting algorithm",
    "definition": "Is an algorithm that puts elements of a list in a certain order. The most frequently used orders are numerical order and lexicographical order. Efficient sorting is important for optimizing the efficiency of other algorithms (such as search and merge algorithms) that require input data to be in sorted lists. Sorting is also often useful for canonicalizing data and for producing human- readable output. More formally, the output of any sorting algorithm must satisfy two conditions: 1. The output is in nondecreasing order (each element is no smaller than the previous element"
  },
  {
    "term": "source code",
    "definition": "In computing, source code is any collection of code, with or without comments, written using[216] a human-readable programming language, usually as plain text. The source code of a program is specially designed to facilitate the work of computer programmers, who specify the actions to be performed by a computer mostly by writing source code. The source code is often transformed by an assembler or compiler into binary machine code that can be executed by the computer. The machine code might then be stored for execution at a later time. Alternatively, source code may be interpreted and thus immediately executed."
  },
  {
    "term": "sparse dictionary learning",
    "definition": "A feature learning method aimed at finding a sparse representation of the input data in the form of a linear combination of basic elements as well as those basic elements themselves."
  },
  {
    "term": "spatial-temporal reasoning",
    "definition": "An area of artificial intelligence which draws from the fields of computer science, cognitive science, and cognitive psychology. The theoretic goal-on the cognitive side-involves representing and reasoning spatial-temporal knowledge in mind. The applied goal-on the computing side-involves developing high-level control systems of automata for navigating and understanding time and space. SPARQL An RDF query language-that is, a semantic query language for databases-able to retrieve and manipulate data stored in Resource Description Framework (RDF)"
  },
  {
    "term": "speech recognition",
    "definition": "An interdisciplinary subfield of computational linguistics that develops methodologies and technologies that enables the recognition and translation of spoken language into text by computers. It is also known as automatic speech recognition (ASR), computer speech recognition or speech to text (STT). It incorporates knowledge and research in the linguistics, computer science, and electrical engineering fields."
  },
  {
    "term": "spiking neural network (SNN)",
    "definition": "An artificial neural network that more closely mimics a natural neural network.[320] In addition to neuronal and synaptic state, SNNs incorporate the concept of time into their Operating Model."
  },
  {
    "term": "spiral model",
    "definition": "Is a risk-driven software development process model. Based on the unique risk patterns of a given project, the spiral model guides a team to adopt elements of one or more process models, such as incremental, waterfall, or evolutionary prototyping."
  },
  {
    "term": "stack",
    "definition": "Is an abstract data type that serves as a collection of elements, with two main principal"
  },
  {
    "term": "Stanford Research Institute Problem Solver (STRIPS)",
    "definition": "An automated planner developed by Richard Fikes and Nils Nilsson in 1971 at SRI International."
  },
  {
    "term": "state",
    "definition": "In information technology and computer science, a system is described as stateful if it is designed to remember preceding events or user interactions;[219] the remembered information is called the state of the system."
  },
  {
    "term": "statement",
    "definition": "In computer programming, a statement is a syntactic unit of an imperative programming language that expresses some action to be carried out.[220] A program written in such a language is formed by a sequence of one or more statements. A statement may have internal components (e.g., expressions)."
  },
  {
    "term": "state–action–reward–state–action (SARSA)",
    "definition": "A reinforcement learning algorithm for learning a Markov decision process policy."
  },
  {
    "term": "statistical classification",
    "definition": "In machine learning and statistics, classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known. Examples are assigning a given email to the \"spam\" or \"non-spam\" class, and assigning a diagnosis to a given patient based on observed characteristics of the patient (sex, blood pressure, presence or absence of certain symptoms, etc.). Classification is an example of pattern recognition."
  },
  {
    "term": "statistical relational learning (SRL)",
    "definition": "A subdiscipline of artificial intelligence and machine learning that is concerned with domain models that exhibit both uncertainty (which can be dealt with using statistical methods) and complex, relational structure.[322][323] Note that SRL is sometimes called Relational Machine Learning (RML) in the literature. Typically, the knowledge representation formalisms developed in SRL use (a subset of) first-order logic to describe relational properties of a domain in a general manner (universal quantification) and draw upon probabilistic graphical models (such as Bayesian networks or Markov networks) to model the uncertainty; some also build upon the methods of inductive logic programming."
  },
  {
    "term": "stochastic optimization (SO)",
    "definition": "Any optimization method that generates and uses random variables. For stochastic problems, the random variables appear in the formulation of the optimization problem itself, which involves random objective functions or random constraints. Stochastic optimization methods also include methods with random iterates. Some stochastic optimization methods use random iterates to solve stochastic problems, combining both meanings of stochastic optimization.[324] Stochastic optimization methods generalize deterministic methods for deterministic problems."
  },
  {
    "term": "stochastic semantic analysis",
    "definition": "An approach used in computer science as a semantic component of natural language understanding. Stochastic models generally use the definition of segments of words as basic semantic units for the semantic models, and in some cases involve a two layered"
  },
  {
    "term": "storage",
    "definition": "Computer data storage is a technology consisting of computer components and recording media that are used to retain digital data. It is a core function and fundamental component of"
  },
  {
    "term": "stream",
    "definition": "Is a sequence of data elements made available over time. A stream can be thought of as items on a conveyor belt being processed one at a time rather than in large batches."
  },
  {
    "term": "string",
    "definition": "In computer programming, a string is traditionally a sequence of characters, either as a literal constant or as some kind of variable. The latter may allow its elements to be mutated and the length changed, or it may be fixed (after creation). A string is generally considered as a data type and is often implemented as an array data structure of bytes (or words) that stores a sequence of elements, typically characters, using some character encoding. String may also denote more general arrays or other sequence (or list) data types and structures."
  },
  {
    "term": "structured storage",
    "definition": "A NoSQL (originally referring to \"non-SQL\" or \"non-relational\")[221] database provides a mechanism for storage and retrieval of data that is modeled in means other than the tabular relations used in relational databases. Such databases have existed since the late 1960s, but the name \"NoSQL\" was only coined in the early 21st century,[222] triggered by the needs of Web 2.0 companies.[223][224] NoSQL databases are increasingly used in big data and real-time web applications.[225] NoSQL systems are also sometimes called \"Not only SQL\" to emphasize that they may support SQL-like query languages or sit alongside SQL databases in polyglot-"
  },
  {
    "term": "subject-matter expert (SME)",
    "definition": "A person who has accumulated great knowledge in a particular field or topic, demonstrated by the person's degree, licensure, and/or through years of professional experience with the subject."
  },
  {
    "term": "subroutine",
    "definition": "In computer programming, a subroutine is a sequence of program instructions that performs a specific task, packaged as a unit. This unit can then be used in programs wherever that particular task should be performed. Subroutines may be defined within programs, or separately in libraries that can be used by many programs. In different programming languages, a subroutine may be called a routine, subprogram, function, method, or procedure. Technically, these terms all have different definitions. The generic, umbrella term callable unit is sometimes"
  },
  {
    "term": "superintelligence",
    "definition": "A hypothetical agent that possesses intelligence far surpassing that of the brightest and most gifted human minds. Superintelligence may also refer to a property of problem- solving systems (e.g., superintelligent language translators or engineering assistants) whether or not these high-level intellectual competencies are embodied in agents that act within the physical world. A superintelligence may or may not be created by an intelligence explosion and be associated with a technological singularity."
  },
  {
    "term": "supervised learning",
    "definition": "The machine learning task of learning a function that maps an input to an output based on example input-output pairs.[326] It infers a function from labeled training data consisting of a set of training examples.[327] In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way (see inductive bias)."
  },
  {
    "term": "support vector machines",
    "definition": "In machine learning, support vector machines (SVMs, also support vector networks[328]) are supervised learning models with associated learning algorithms that analyze data used for classification and regression."
  },
  {
    "term": "swarm intelligence (SI)",
    "definition": "The collective behavior of decentralized, self-organized systems, either natural or artificial. The expression was introduced in the context of cellular robotic systems.[329]"
  },
  {
    "term": "symbolic artificial intelligence",
    "definition": "The term for the collection of all methods in artificial intelligence research that are based on high-level \"symbolic\" (human-readable) representations of problems, logic, and search."
  },
  {
    "term": "symbolic computation",
    "definition": "In mathematics and computer science,[228] computer algebra, also called symbolic computation or algebraic computation, is a scientific area that refers to the study and development of algorithms and software for manipulating mathematical expressions and other mathematical objects. Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating-point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols."
  },
  {
    "term": "syntax",
    "definition": "The syntax of a computer language is the set of rules that defines the combinations of symbols that are considered to be correctly structured statements or expressions in that language. This applies both to programming languages, where the document represents source code, and to markup languages, where the document represents data."
  },
  {
    "term": "syntax error",
    "definition": "Is an error in the syntax of a sequence of characters or tokens that is intended to be written in compile-time. A program will not compile until all syntax errors are corrected. For interpreted languages, however, a syntax error may be detected during program execution, and an interpreter's error messages might not differentiate syntax errors from errors of other kinds. There is some disagreement as to just what errors are \"syntax errors\". For example, some would say that the use of an uninitialized variable's value in Java code is a syntax error, but many others would disagree[229][230] and would classify this as a (static) semantic error."
  },
  {
    "term": "synthetic intelligence (SI)",
    "definition": "An alternative term for artificial intelligence which emphasizes that the intelligence of machines need not be an imitation or in any way artificial; it can be a genuine form of"
  },
  {
    "term": "system console",
    "definition": "The system console, computer console, root console, operator's console, or simply console is the text entry and display device for system administration messages, particularly those from the BIOS or boot loader, the kernel, from the init system and from the system logger. It is a physical device consisting of a keyboard and a screen, and traditionally is a text terminal, but may also be a graphical terminal. System consoles are generalized to computer terminals, which are abstracted respectively by virtual consoles and terminal emulators. Today communication with system consoles is generally done abstractly, via the standard streams (stdin, stdout, and stderr), but there may be system-specific interfaces, for example those used by the system kernel. T"
  },
  {
    "term": "systems neuroscience",
    "definition": "A subdiscipline of neuroscience and systems biology that studies the structure and function of neural circuits and systems. It is an umbrella term, encompassing a number of areas of study concerned with how nerve cells behave when connected together to form neural pathways, neural circuits, and larger brain networks. T"
  },
  {
    "term": "technical documentation",
    "definition": "In engineering, any type of documentation that describes handling, functionality, and architecture of a technical product or a product under development or use.[231][232][233] The intended recipient for product technical documentation is both the (proficient) end user as well as the administrator/service or maintenance technician. In contrast to a mere \"cookbook\" manual, technical documentation aims at providing enough information for a user to understand inner and outer dependencies of the product at hand."
  },
  {
    "term": "technological singularity",
    "definition": "A hypothetical point in the future when technological growth becomes uncontrollable and irreversible, resulting in unfathomable changes to human civilization.[332][333][334]"
  },
  {
    "term": "temporal difference learning",
    "definition": "A class of model-free reinforcement learning methods which learn by bootstrapping from the current estimate of the value function. These methods sample from the environment, like Monte Carlo methods, and perform updates based on current estimates, like dynamic"
  },
  {
    "term": "tensor network theory",
    "definition": "A theory of brain function (particularly that of the cerebellum) that provides a mathematical model of the transformation of sensory space-time coordinates into motor coordinates and vice versa by cerebellar neuronal networks. The theory was developed as a geometrization of brain function (especially of the central nervous system) using"
  },
  {
    "term": "tensors.[336][337]",
    "definition": "TensorFlow A free and open-source software library for dataflow and differentiable programming across a range of tasks. It is a symbolic math library, and is also used for machine"
  },
  {
    "term": "that can be represented exactly is of the following form:",
    "definition": "where significand is an integer, base is an integer greater than or equal to two, and exponent is"
  },
  {
    "term": "them.[259]",
    "definition": "NP In computational complexity theory, NP (nondeterministic polynomial time) is a complexity class used to classify decision problems. NP is the set of decision problems for which the problem instances, where the answer is \"yes\", have proofs verifiable in polynomial"
  },
  {
    "term": "theoretical computer science (TCS)",
    "definition": "A subset of general computer science and mathematics that focuses on more mathematical topics of computing and includes the theory of computation."
  },
  {
    "term": "theory of computation",
    "definition": "In theoretical computer science and mathematics, the theory of computation is the branch that deals with how efficiently problems can be solved on a model of computation, using an algorithm. The field is divided into three major branches: automata theory and languages, computability theory, and computational complexity theory, which are linked by the question: \"What are the fundamental capabilities and limitations of computers?\".[339]"
  },
  {
    "term": "third-generation programming language",
    "definition": "A third-generation programming language (3GL) is a high-level computer programming language that tends to be more machine-independent and programmer-friendly than the machine code of the first-generation and assembly languages of the second-generation, while having a less specific focus to the fourth and fifth generations.[234] Examples of common and historical third-generation programming languages are ALGOL, BASIC, C, COBOL, Fortran, Java, and Pascal."
  },
  {
    "term": "Thompson sampling",
    "definition": "A heuristic for choosing actions that addresses the exploration-exploitation dilemma in the multi-armed bandit problem. It consists in choosing the action that maximizes the expected reward with respect to a randomly drawn belief.[340][341]"
  },
  {
    "term": "time complexity",
    "definition": "The computational complexity that describes the amount of time it takes to run an algorithm. Time complexity is commonly estimated by counting the number of elementary operations performed by the algorithm, supposing that each elementary operation takes a fixed amount of time to perform. Thus, the amount of time taken and the number of elementary operations performed by the algorithm are taken to differ by at most a constant factor."
  },
  {
    "term": "time.[260][Note 1]",
    "definition": "NP-completeness In computational complexity theory, a problem is NP-complete when it can be solved by a restricted class of brute force search algorithms and it can be used to simulate any other problem with a similar algorithm. More precisely, each input to the problem should be associated with a set of solutions of polynomial length, whose validity can be tested quickly (in polynomial time[261]), such that the output for any input is \"yes\" if the solution set is non-empty and \"no\" if it is empty. NP-hardness In computational complexity theory, the defining property of a class of problems that are, informally, \"at least as hard as the hardest problems in NP\". A simple example of an NP- hard problem is the subset sum problem. O Occam's razor The problem-solving principle that states that when presented with competing hypotheses that make the same predictions, one should select the solution with the fewest assumptions;[262] the principle is not meant to filter out hypotheses that make different predictions. The idea is attributed to the English Franciscan friar William of Ockham (c. 1287–1347), a scholastic philosopher and theologian."
  },
  {
    "term": "transfer learning",
    "definition": "A machine learning technique in which knowledge learned from a task is reused in order to boost performance on a related task.[342] For example, for image classification, knowledge gained while learning to recognize cars could be applied when trying to recognize trucks."
  },
  {
    "term": "transformer",
    "definition": "A type of deep learning architecture that exploits a multi-head attention mechanism. Transformers address some of the limitations of long short-term memory, and became widely used in natural language processing, although it can also process other types of"
  },
  {
    "term": "transhumanism",
    "definition": "An international philosophical movement that advocates for the transformation of the human condition by developing and making widely available sophisticated technologies to"
  },
  {
    "term": "transition system",
    "definition": "In theoretical computer science, a transition system is a concept used in the study of computation. It is used to describe the potential behavior of discrete systems. It consists of states and transitions between states, which may be labeled with labels chosen from a set; the same label may appear on more than one transition. If the label set is a singleton, the system is essentially unlabeled, and a simpler definition that omits the labels is possible."
  },
  {
    "term": "tree",
    "definition": "A widely used abstract data type (ADT) that simulates a hierarchical tree structure, with a root value and subtrees of children with a parent node, represented as a set of linked nodes."
  },
  {
    "term": "tree traversal",
    "definition": "A form of graph traversal and refers to the process of visiting (checking and/or updating) each node in a tree data structure, exactly once. Such traversals are classified by the order in which the nodes are visited."
  },
  {
    "term": "true quantified Boolean formula",
    "definition": "In computational complexity theory, the language TQBF is a formal language consisting of the true quantified Boolean formulas. A (fully) quantified Boolean formula is a formula in quantified propositional logic where every variable is quantified (or bound), using either existential or universal quantifiers, at the beginning of the sentence. Such a formula is equivalent to either true or false (since there are no free variables). If such a formula evaluates to true, then that formula is in the language TQBF. It is also known as QSAT (Quantified SAT)."
  },
  {
    "term": "Turing machine",
    "definition": "A mathematical model of computation describing an abstract machine[346] that manipulates symbols on a strip of tape according to a table of rules.[347] Despite the model's simplicity, it is capable of implementing any algorithm.[348]"
  },
  {
    "term": "Turing test",
    "definition": "A test of a machine's ability to exhibit intelligent behaviour equivalent to, or indistinguishable from, that of a human, developed by Alan Turing in 1950. Turing proposed that a human evaluator would judge natural language conversations between a human and a machine designed to generate human-like responses. The evaluator would be aware that one of the two partners in conversation is a machine, and all participants would be separated from one another. The conversation would be limited to a text-only channel such as a computer keyboard and screen so the result would not depend on the machine's ability to render words as speech.[349] If the evaluator cannot reliably tell the machine from the human, the machine is said to have passed the test. The test results do not depend on the machine's ability to give correct answers to questions, only how closely its answers resemble those a human would give."
  },
  {
    "term": "type system",
    "definition": "In programming languages, a set of rules that assigns a property called type to the various constructs of a computer program, such as variables, expressions, functions, or modules.[350] These types formalize and enforce the otherwise implicit categories the programmer uses for algebraic data types, data structures, or other components (e.g. \"string\", \"array of float\", \"function returning boolean\"). The main purpose of a type system is to reduce possibilities for bugs in computer programs[351] by defining interfaces between different parts of a computer program, and then checking that the parts have been connected in a consistent way. This checking can happen statically (at compile time), dynamically (at run time), or as a combination of static and dynamic checking. Type systems have other purposes as well, such as expressing business rules, enabling certain compiler optimizations, allowing for multiple dispatch, providing a form of documentation, etc. U"
  },
  {
    "term": "type theory",
    "definition": "In mathematics, logic, and computer science, a type theory is any of a class of formal systems, some of which can serve as alternatives to set theory as a foundation for all mathematics. In type theory, every \"term\" has a \"type\" and operations are restricted to terms of a certain type. U"
  },
  {
    "term": "Uniform Resource Locator (URL)",
    "definition": "A reference to a web resource that specifies its location on a computer network and a mechanism for retrieving it. A URL is a specific type of Uniform Resource Identifier (URI),[237][238] although many people use the two terms interchangeably.[239][c] URLs occur most commonly to reference web pages (http), but are also used for file transfer (ftp), email (mailto), database access (JDBC), and many other applications."
  },
  {
    "term": "unique",
    "definition": "An element that is different from other elements. Database records are kept separate using unique keys. A set guarantees that all its elements are unique. The existence of a unique element is modeled using uniqueness quantification. Finding unique elements in a sequence or list requires data deduplication. Contrast singleton."
  },
  {
    "term": "unsupervised learning",
    "definition": "A type of self-organized Hebbian learning that helps find previously unknown patterns in data set without pre-existing labels. It is also known as self-organization and allows modeling probability densities of given inputs.[352] It is one of the three basic paradigms of machine learning, alongside supervised and reinforcement learning. Semi-supervised learning has also been described and is a hybridization of supervised and unsupervised techniques. V"
  },
  {
    "term": "upload",
    "definition": "In computer networks, to send data to a remote system such as a server or another client so that the remote system can store a copy.[235] Contrast download."
  },
  {
    "term": "user",
    "definition": "Is a person who utilizes a computer or network service. Users of computer systems and software products generally lack the technical expertise required to fully understand how they work.[242] Power users use advanced features of programs, though they are not necessarily capable of computer programming and system administration."
  },
  {
    "term": "user agent",
    "definition": "Software (a software agent) that acts on behalf of a user, such as a web browser that \"retrieves, renders and facilitates end user interaction with Web content\".[243] An email reader is a mail user agent."
  },
  {
    "term": "user interface (UI)",
    "definition": "The space where interactions between humans and machines occur. The goal of this interaction is to allow effective operation and control of the machine from the human end, whilst the machine simultaneously feeds back information that aids the operators' decision-making process. Examples of this broad concept of user interfaces include the interactive aspects of computer operating systems, hand tools, heavy machinery operator controls, and process controls. The design considerations applicable when creating user interfaces are related to or involve such disciplines as ergonomics and psychology."
  },
  {
    "term": "user interface design",
    "definition": "The design of user interfaces for machines and software, such as computers, home appliances, mobile devices, and other electronic devices, with the focus on maximizing usability and the user experience. The goal of user interface design is to make the user's interaction as simple and efficient as possible, in terms of accomplishing user goals (user-centered design). V"
  },
  {
    "term": "V-Model",
    "definition": "A software development process that may be considered an extension of the waterfall model, and is an example of the more general V-model. Instead of moving down in a linear way, the process steps are bent upwards after the coding phase, to form the typical V shape. The V- Model demonstrates the relationships between each phase of the development life cycle and its associated phase of testing. The horizontal and vertical axes represent time or project completeness (left-to-right) and level of abstraction (coarsest-grain abstraction uppermost), respectively"
  },
  {
    "term": "Value-alignment complete",
    "definition": "Analogous to an AI-complete problem, a value-alignment complete problem is a problem where the AI control problem needs to be fully solved to solve it. W Watson A question-answering computer system capable of answering questions posed in natural language,[355] developed in IBM's DeepQA project by a research team led by principal investigator David Ferrucci.[356] Watson was named after IBM's first CEO, industrialist Thomas J. Watson.[357][358]"
  },
  {
    "term": "variable",
    "definition": "In computer programming, a variable, or scalar, is a storage location (identified by a memory address) paired with an associated symbolic name (an identifier), which contains some known or unknown quantity of information referred to as a value. The variable name is the usual way to reference the stored value, in addition to referring to the variable itself, depending on the context. This separation of name and content allows the name to be used independently of the exact information it represents. The identifier in computer source code can be bound to a value during run time, and the value of the variable may therefore change during the course of"
  },
  {
    "term": "virtual machine (VM)",
    "definition": "An emulation of a computer system. Virtual machines are based on computer architectures and attempt to provide the same functionality as a physical computer. Their implementations may involve specialized hardware, software, or a combination of both."
  },
  {
    "term": "vision processing unit (VPU)",
    "definition": "A type of microprocessor designed to accelerate machine vision tasks.[353][354]"
  },
  {
    "term": "waterfall model",
    "definition": "A breakdown of project activities into linear sequential phases, where each phase depends on the deliverables of the previous one and corresponds to a specialisation of tasks. The approach is typical for certain areas of engineering design. In software development, it tends to be among the less iterative and flexible approaches, as progress flows in largely one direction (\"downwards\" like a waterfall) through the phases of conception, initiation, analysis, design, construction, testing, deployment and maintenance."
  },
  {
    "term": "Waveform Audio File Format",
    "definition": "An audio file format standard, developed by Microsoft and IBM, for storing an audio bitstream on PCs. It is an application of the Resource Interchange File Format (RIFF) bitstream format method for storing data in \"chunks\", and thus is also close to the 8SVX and the AIFF format used on Amiga and Macintosh computers, respectively. It is the main format used on Microsoft Windows systems for raw and typically uncompressed audio. The usual bitstream encoding is the linear pulse-code modulation (LPCM) format."
  },
  {
    "term": "weak AI",
    "definition": "Artificial intelligence that is focused on one narrow task.[359][360][361]"
  },
  {
    "term": "weak supervision",
    "definition": "See semi-supervised learning."
  },
  {
    "term": "web crawler",
    "definition": "An Internet bot that systematically browses the World Wide Web, typically for the purpose of Web indexing (web spidering)."
  },
  {
    "term": "Wi-Fi",
    "definition": "A family of wireless networking technologies, based on the IEEE 802.11 family of standards, which are commonly used for local area networking of devices and Internet access. Wi‑Fi is a trademark of the non-profit Wi-Fi Alliance, which restricts the use of the term Wi-Fi Certified to products that successfully complete interoperability certification testing"
  },
  {
    "term": "word embedding",
    "definition": "A representation of a word in natural language processing. Typically, the representation is a real-valued vector that encodes the meaning of the word in such a way that words that are closer in the vector space are expected to be similar in meaning."
  },
  {
    "term": "XGBoost",
    "definition": "Short for eXtreme Gradient Boosting, XGBoost is an open-source software library which provides a regularizing gradient boosting framework for multiple programming languages."
  },
  {
    "term": "XHTML",
    "definition": "Part of the family of XML markup languages. It mirrors or extends versions of the widely used HyperText Markup Language (HTML), the language in which web pages are formulated."
  }
]